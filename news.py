# ============================================================================================================
# IMPORT & ENV
# ============================================================================================================
import os
import re
import json
import time
import random
from datetime import datetime, timedelta
from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode

import feedparser
from dateutil import parser as dateutil_parser
import pytz
import requests
import google.generativeai as genai

try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "").strip()

if not GEMINI_API_KEY:
    raise RuntimeError("‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY")

if not LINE_CHANNEL_ACCESS_TOKEN:
    raise RuntimeError("‡πÑ‡∏°‡πà‡∏û‡∏ö LINE_CHANNEL_ACCESS_TOKEN")

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel(os.getenv("GEMINI_MODEL_NAME", "gemini-2.5-flash"))

GEMINI_DAILY_BUDGET = int(os.getenv("GEMINI_DAILY_BUDGET", "250"))
MAX_RETRIES = 6
SLEEP_BETWEEN_CALLS = (6.0, 7.0)
DRY_RUN = os.getenv("DRY_RUN", "false").lower() == "true"

bangkok_tz = pytz.timezone("Asia/Bangkok")
now = datetime.now(bangkok_tz)

S = requests.Session()
S.headers.update({"User-Agent": "Mozilla/5.0"})
TIMEOUT = 15

SENT_LINKS_DIR = "sent_links"
os.makedirs(SENT_LINKS_DIR, exist_ok=True)


# ============================================================================================================
# HELPERS
# ============================================================================================================
def _normalize_link(url: str) -> str:
    try:
        p = urlparse(url)
        netloc = p.netloc.lower()
        scheme = (p.scheme or "https").lower()
        drop = {"fbclid", "gclid", "ref", "mc_cid", "mc_eid"}
        new_q = [
            (k, v)
            for k, v in parse_qsl(p.query, keep_blank_values=True)
            if not (k.startswith("utm_") or k in drop)
        ]
        return urlunparse(p._replace(scheme=scheme, netloc=netloc, query=urlencode(new_q)))
    except Exception:
        return (url or "").strip()


def get_sent_links_file(date=None):
    if date is None:
        date = datetime.now(bangkok_tz).strftime("%Y-%m-%d")
    return os.path.join(SENT_LINKS_DIR, f"{date}.txt")


def load_sent_links():
    sent = set()
    for i in range(2):
        d = (now - timedelta(days=i)).strftime("%Y-%m-%d")
        p = get_sent_links_file(d)
        if os.path.exists(p):
            with open(p, "r", encoding="utf-8") as f:
                for line in f:
                    u = _normalize_link(line.strip())
                    if u:
                        sent.add(u)
    return sent


def save_sent_links(links):
    p = get_sent_links_file()
    with open(p, "a", encoding="utf-8") as f:
        for l in links:
            f.write(_normalize_link(l) + "\n")


def _impact_to_bullets(text: str):
    if not text:
        return ["‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö"]
    raw = text.strip()
    parts = []
    for line in raw.splitlines():
        if line.strip():
            parts.append(line.strip("‚Ä¢- ‚Äî\t "))
    if len(parts) <= 1:
        tmp = re.split(r"[„ÄÇÔºé\.]\s*", raw)
        parts = [t.strip("‚Ä¢- ") for t in tmp if t.strip()]
    return parts or ["‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö"]


# ============================================================================================================
# CONTEXT
# ============================================================================================================
PTT_CONTEXT = """
‡πÇ‡∏ü‡∏Å‡∏±‡∏™‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‚Äú‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á ‡∏õ‡∏ï‡∏ó.‚Äù ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏¢‡∏Å‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏•‡∏π‡∏Å ‡πÄ‡∏ä‡πà‡∏ô PTTEP / PTTLNG / PTTGL / PTTNGD / TTM

‡∏Ç‡∏≠‡∏ö‡πÄ‡∏Ç‡∏ï‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏´‡∏•‡∏±‡∏Å:
- ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÅ‡∏•‡∏∞ LNG
- ‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ LNG
- ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡πà‡∏≠‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®
- ‡πÇ‡∏£‡∏á‡πÅ‡∏¢‡∏Å‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (GSP)
- ‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡∏Å‡πä‡∏≤‡∏ã‡πÉ‡∏´‡πâ‡πÇ‡∏£‡∏á‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ ‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏° ‡πÅ‡∏•‡∏∞ NGV

‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏Ç‡πà‡∏≤‡∏ß ‚Äú‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‚Äù ‡∏´‡∏≤‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡πâ‡∏≠:
1) ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Å‡πä‡∏≤‡∏ã / LNG / ‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏ú‡∏±‡∏ô‡∏ú‡∏ß‡∏ô‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á
2) ‡∏ã‡∏±‡∏û‡∏û‡∏•‡∏≤‡∏¢‡∏Å‡πä‡∏≤‡∏ã‡∏™‡∏∞‡∏î‡∏∏‡∏î ‡πÄ‡∏ä‡πà‡∏ô ‡∏ó‡πà‡∏≠‡∏Å‡πä‡∏≤‡∏ã‡πÄ‡∏™‡∏µ‡∏¢, ‡πÇ‡∏£‡∏á‡πÅ‡∏¢‡∏Å‡∏´‡∏¢‡∏∏‡∏î‡∏ú‡∏•‡∏¥‡∏ï, ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå geopolitical ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö supply
3) ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏≤‡∏ô‡∏Å‡πä‡∏≤‡∏ã: LNG terminal, FSRU, Pipeline, Gas Processing
4) ‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏£‡∏±‡∏ê‡∏î‡πâ‡∏≤‡∏ô‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡∏Å‡πä‡∏≤‡∏ã‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏Å‡πä‡∏≤‡∏ã‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®

‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏ô‡πÉ‡∏à‡∏Ç‡πà‡∏≤‡∏ß downstream, ‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ, EV, PR, ‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î
"""


# ============================================================================================================
# GEMINI CALL WRAPPER
# ============================================================================================================
GEMINI_CALLS = 0

def call_gemini(prompt):
    global GEMINI_CALLS
    if GEMINI_CALLS >= GEMINI_DAILY_BUDGET:
        raise RuntimeError("‡πÄ‡∏Å‡∏¥‡∏ô‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤ Gemini ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô")

    last_error = None
    for i in range(1, MAX_RETRIES + 1):
        try:
            r = model.generate_content(prompt)
            GEMINI_CALLS += 1
            return r
        except Exception as e:
            last_error = e
            if any(x in str(e) for x in ["429", "unavailable", "deadline", "503", "500"]) and i < MAX_RETRIES:
                time.sleep(5 * i)
                continue
            raise e
    raise last_error


# ============================================================================================================
# FILTER ‚Üí ‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
# ============================================================================================================
def llm_filter(news):
    prompt = f"""
{PTT_CONTEXT}

‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: News Screener ‡∏Ç‡∏≠‡∏á ‡∏õ‡∏ï‡∏ó.
‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà: ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ ‚Äú‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á ‡∏õ‡∏ï‡∏ó. ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‚Äù

‡∏Ç‡πà‡∏≤‡∏ß:
‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {news['title']}
‡∏™‡∏£‡∏∏‡∏õ: {news['summary']}
‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: {news.get('detail','')}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß:
- ‡πÉ‡∏ä‡πà
- ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà
"""
    try:
        r = call_gemini(prompt)
        ans = (r.text or "").strip().replace("\n", "")
        return ans.startswith("‡πÉ‡∏ä‡πà")
    except Exception:
        return False


# ============================================================================================================
# TAG ‡∏Ç‡πà‡∏≤‡∏ß (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏•‡∏π‡∏Å)
# ============================================================================================================
def gemini_tag(news):
    schema = {
        "type": "object",
        "properties": {
            "summary": {"type": "string"},
            "topic_type": {
                "type": "string",
                "enum": [
                    "supply_disruption", "price_move", "policy",
                    "investment", "geopolitics", "other"
                ]
            },
            "region": {
                "type": "string",
                "enum": ["global", "asia", "europe", "middle_east", "us", "other"]
            },
            "impact_reason": {"type": "string"}
        },
        "required": ["summary", "topic_type", "region", "impact_reason"]
    }

    prompt = f"""
{PTT_CONTEXT}

‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡πÅ‡∏•‡∏∞‡∏ï‡∏≠‡∏ö JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:

‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {news['title']}
‡∏™‡∏£‡∏∏‡∏õ RSS: {news['summary']}
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°: {news.get('detail','')}

‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç:
- summary = ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
- topic_type = ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å enum
- region = ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å enum
- impact_reason = ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠ ‚Äú‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á ‡∏õ‡∏ï‡∏ó.‚Äù
  *‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô bullet point ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î*

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡∏ï‡∏≤‡∏° schema ‡∏ô‡∏µ‡πâ:
{json.dumps(schema, ensure_ascii=False)}
"""

    try:
        r = call_gemini(prompt)
        raw = (r.text or "").strip()
        if raw.startswith("```"):
            raw = re.sub(r"^```(json)?", "", raw).strip()
            raw = re.sub(r"```$","", raw).strip()
        return json.loads(raw)
    except Exception:
        return {
            "summary": news['summary'],
            "topic_type": "other",
            "region": "other",
            "impact_reason": "-"
        }


# ============================================================================================================
# FETCH NEWS
# ============================================================================================================
NEWS_FEEDS = [
    ("Oilprice", "Energy", "https://oilprice.com/rss/main"),
    ("CleanTechnica", "Energy", "https://cleantechnica.com/feed/"),
    ("HydrogenFuelNews", "Energy", "https://www.hydrogenfuelnews.com/feed/"),
    ("Economist", "Economy", "https://www.economist.com/latest/rss.xml"),
    ("YahooFinance", "Economy", "https://finance.yahoo.com/news/rssindex"),
]

def fetch_news_window():
    now_local = datetime.now(bangkok_tz)
    start = (now_local - timedelta(days=1)).replace(
        hour=21, minute=0, second=0, microsecond=0
    )
    end = now_local.replace(hour=6, minute=0, second=0, microsecond=0)

    out = []
    for site, cat, url in NEWS_FEEDS:
        try:
            feed = feedparser.parse(url)
            for e in feed.entries:
                pub = getattr(e, "published", None) or getattr(e, "updated", None)
                if not pub:
                    continue
                dt = dateutil_parser.parse(pub)
                if dt.tzinfo is None:
                    dt = pytz.UTC.localize(dt)
                dt = dt.astimezone(bangkok_tz)
                if start <= dt <= end:
                    out.append({
                        "site": site,
                        "category": cat,
                        "title": e.title,
                        "summary": getattr(e, "summary", ""),
                        "link": e.link,
                        "published": dt,
                        "date": dt.strftime("%d/%m/%Y %H:%M")
                    })
        except Exception:
            pass

    uniq = []
    seen = set()
    for n in out:
        k = _normalize_link(n['link'])
        if k not in seen:
            seen.add(k)
            uniq.append(n)
    return uniq


# ============================================================================================================
# GROUP NEWS
# ============================================================================================================
def group_news(news_list, min_size=3):
    buckets = {}
    for n in news_list:
        key = (n.get("topic_type"), n.get("region"))
        buckets.setdefault(key, []).append(n)

    out = []
    for (topic, region), items in buckets.items():
        if len(items) >= min_size:
            items_sorted = sorted(items, key=lambda x: x['published'], reverse=True)
            anchor = items_sorted[0]
            out.append({
                "is_group": True,
                "topic_type": topic,
                "region": region,
                "news_items": items_sorted,
                "title": anchor['title'],
                "site": "‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß",
                "category": anchor['category'],
                "date": anchor['date'],
                "published": anchor['published'],
                "link": anchor['link']
            })
        else:
            out.extend(items)
    return out


# ============================================================================================================
# SUMMARIZE GROUP
# ============================================================================================================
def gemini_group_summary(group):
    block = "\n".join([f"- {n['title']}: {n['summary']}" for n in group['news_items']])

    prompt = f"""
{PTT_CONTEXT}

‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:
{block}

‡∏ï‡∏≠‡∏ö JSON:
{{
 "summary": "<‡∏™‡∏£‡∏∏‡∏õ>",
 "impact_reason": "<‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡πÄ‡∏õ‡πá‡∏ô bullet>"
}}
"""

    try:
        r = call_gemini(prompt)
        raw = (r.text or "").strip()
        if raw.startswith("```"):
            raw = re.sub(r"^```(json)?","", raw).strip()
            raw = re.sub(r"```$","", raw).strip()
        return json.loads(raw)
    except Exception:
        return {"summary": "‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ", "impact_reason": "-"}


# ============================================================================================================
# FLEX MESSAGE
# ============================================================================================================
def create_flex(news_items):
    now_txt = datetime.now(bangkok_tz).strftime("%d/%m/%Y")
    bubbles = []

    for n in news_items:
        bullets = _impact_to_bullets(n.get("impact_reason", "-"))

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏•‡∏¥‡∏á‡∏Å‡πå ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà http(s) ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ fallback
        link = n.get("link") or ""
        if not (isinstance(link, str) and link.startswith(("http://", "https://"))):
            link = "https://www.google.com/search?q=energy+gas+news"

        impact_box = {
            "type": "box",
            "layout": "vertical",
            "margin": "lg",
            "contents": [
                {
                    "type": "text",
                    "text": "‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó.",
                    "size": "lg",
                    "weight": "bold",
                    "color": "#D32F2F"
                }
            ] + [
                {
                    "type": "text",
                    "text": f"‚Ä¢ {b}",
                    "wrap": True,
                    "size": "md",
                    "color": "#C62828",
                    "weight": "bold",
                    "margin": "xs"
                }
                for b in bullets
            ]
        }

        bubble = {
            "type": "bubble",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {"type": "text", "text": n['title'], "weight": "bold", "size": "lg", "wrap": True},
                    {"type": "text", "text": f"üóì {n['date']}", "size": "xs", "color": "#888888", "margin": "sm"},
                    {"type": "text", "text": f"üåç {n['site']}", "size": "xs", "color": "#448AFF", "margin": "xs"},
                    {
                        "type": "text",
                        "text": f"‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {n['topic_type']} | ‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ: {n['region']}",
                        "size": "xs",
                        "color": "#555555",
                        "margin": "sm"
                    },
                    impact_box
                ]
            },
            "footer": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {
                        "type": "button",
                        "style": "primary",
                        "color": "#1DB446",
                        "action": {
                            "type": "uri",
                            "label": "‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡πà‡∏≠",
                            "uri": link
                        }
                    }
                ]
            }
        }
        bubbles.append(bubble)

    return [{
        "type": "flex",
        "altText": f"‡∏Ç‡πà‡∏≤‡∏ß ‡∏õ‡∏ï‡∏ó. {now_txt}",
        "contents": {
            "type": "carousel",
            "contents": bubbles
        }
    }]


# ============================================================================================================
# BROADCAST LINE (‡πÄ‡∏û‡∏¥‡πà‡∏° debug payload + response body)
# ============================================================================================================
def send_to_line(messages):
    url = "https://api.line.me/v2/bot/message/broadcast"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}"
    }

    for i, msg in enumerate(messages, 1):
        payload = {"messages": [msg]}

        # DEBUG: ‡πÅ‡∏™‡∏î‡∏á payload ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ LINE
        print("=== LINE PAYLOAD ===")
        print(json.dumps(payload, ensure_ascii=False, indent=2))

        if DRY_RUN:
            print("[DRY_RUN] ‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ DRY_RUN = true")
            continue

        r = S.post(url, headers=headers, json=payload, timeout=15)
        print(f"Send {i}: {r.status_code}")
        print("Response body:", r.text)

        if r.status_code >= 300:
            break


# ============================================================================================================
# MAIN WORKFLOW
# ============================================================================================================
def main():
    print("‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß...")
    all_news = fetch_news_window()

    filtered = []
    for n in all_news:
        n['detail'] = n['title'] if len(n['summary']) < 50 else ''
        if llm_filter(n):
            filtered.append(n)
        time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))

    if not filtered:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á")
        return

    print("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢ LLM...")
    tagged = []
    for n in filtered:
        tag = gemini_tag(n)
        n['topic_type'] = tag['topic_type']
        n['region'] = tag['region']
        n['impact_reason'] = tag['impact_reason']
        tagged.append(n)
        time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))

    grouped = group_news(tagged)

    for g in grouped:
        if g.get("is_group"):
            meta = gemini_group_summary(g)
            g['impact_reason'] = meta['impact_reason']

    selected = grouped[:10]

    sent = load_sent_links()
    final = [n for n in selected if _normalize_link(n['link']) not in sent]

    if not final:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà")
        return

    msgs = create_flex(final)
    send_to_line(msgs)
    save_sent_links([n['link'] for n in final])

    print("‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")


# ============================================================================================================
if __name__ == "__main__":
    main()
