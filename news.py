import os
import re
import json
import time
import random
from datetime import datetime, timedelta
from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode

import feedparser
from dateutil import parser as dateutil_parser
import pytz
import requests
import google.generativeai as genai

# ===== .env =====
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

# ========================= CONFIG =========================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "").strip()
if not GEMINI_API_KEY:
    raise RuntimeError("‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY ‡πÉ‡∏ô Environment/Secrets")
if not LINE_CHANNEL_ACCESS_TOKEN:
    raise RuntimeError("‡πÑ‡∏°‡πà‡∏û‡∏ö LINE_CHANNEL_ACCESS_TOKEN ‡πÉ‡∏ô Environment/Secrets")

GEMINI_MODEL_NAME = os.getenv("GEMINI_MODEL_NAME", "gemini-2.5-flash").strip() or "gemini-2.5-flash"
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel(GEMINI_MODEL_NAME)

GEMINI_DAILY_BUDGET = int(os.getenv("GEMINI_DAILY_BUDGET", "250"))
MAX_RETRIES = 6
SLEEP_BETWEEN_CALLS = (6.0, 7.0)
DRY_RUN = os.getenv("DRY_RUN", "false").lower() == "true"

bangkok_tz = pytz.timezone("Asia/Bangkok")
now = datetime.now(bangkok_tz)

S = requests.Session()
S.headers.update({"User-Agent": "Mozilla/5.0"})
TIMEOUT = 15

SENT_LINKS_DIR = "sent_links"
os.makedirs(SENT_LINKS_DIR, exist_ok=True)

# ========================= Helpers =========================
def _normalize_link(url: str) -> str:
    try:
        p = urlparse(url)
        netloc = p.netloc.lower()
        scheme = (p.scheme or "https").lower()
        bad_keys = {"fbclid", "gclid", "ref", "ref_", "mc_cid", "mc_eid"}
        q = []
        for k, v in parse_qsl(p.query, keep_blank_values=True):
            if k.startswith("utm_") or k in bad_keys:
                continue
            q.append((k, v))
        return urlunparse(p._replace(scheme=scheme, netloc=netloc, query=urlencode(q)))
    except Exception:
        return (url or "").strip()

def get_sent_links_file(date=None):
    if date is None:
        date = datetime.now(bangkok_tz).strftime("%Y-%m-%d")
    return os.path.join(SENT_LINKS_DIR, f"{date}.txt")

def load_sent_links_today_yesterday():
    sent_links = set()
    for i in range(2):
        date = (now - timedelta(days=i)).strftime("%Y-%m-%d")
        path = get_sent_links_file(date)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                for line in f:
                    url = _normalize_link(line.strip())
                    if url:
                        sent_links.add(url)
    return sent_links

def save_sent_links(new_links, date=None):
    path = get_sent_links_file(date)
    with open(path, "a", encoding="utf-8") as f:
        for url in new_links:
            f.write(_normalize_link(url) + "\n")

def _polish_impact_text(text: str) -> str:
    if not text:
        return text
    text = re.sub(r"\((?:[^)]*(?:‡∏ö‡∏ß‡∏Å|‡∏•‡∏ö|‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô|‡∏™‡∏±‡πâ‡∏ô|‡∏Å‡∏•‡∏≤‡∏á|‡∏¢‡∏≤‡∏ß)[^)]*)\)", "", text)
    text = re.sub(r"\s{2,}", " ", text)
    text = re.sub(r"\s*,\s*,", ", ", text)
    text = re.sub(r"\s*,\s*\.", ".", text)
    return text.strip()

# ========================= FEEDS =========================
news_sources = {
    "Oilprice": {"url": "https://oilprice.com/rss/main", "category": "Energy", "site": "Oilprice"},
    "CleanTechnica": {"url": "https://cleantechnica.com/feed/", "category": "Energy", "site": "CleanTechnica"},
    "HydrogenFuelNews": {"url": "https://www.hydrogenfuelnews.com/feed/", "category": "Energy", "site": "Hydrogen Fuel News"},
    "Economist": {"url": "https://www.economist.com/latest/rss.xml", "category": "Economy", "site": "Economist"},
    "YahooFinance": {"url": "https://finance.yahoo.com/news/rssindex", "category": "Economy", "site": "Yahoo Finance"},
}
DEFAULT_ICON_URL = "https://scdn.line-apps.com/n/channel_devcenter/img/fx/01_1_cafe.png"
GEMINI_CALLS = 0

COLON_RX = re.compile(r"[ÔºöÔπïÍûâÔ∏ì‚¶Ç‚∏øÀ∏]")
def _normalize_colons(text: str) -> str:
    return COLON_RX.sub(":", text or "")

def fetch_article_image(url: str) -> str:
    try:
        r = S.get(url, timeout=TIMEOUT)
        if r.status_code >= 400:
            return ""
        html = r.text
        m = re.search(r'<meta[^>]+property=[\'\"]og:image[\'\"][^>]+content=[\'\"]([^\'\"]+)[\'\"]', html, re.I)
        if m: return m.group(1)
        m = re.search(r'<meta[^>]+name=[\'\"]twitter:image[\'\"][^>]+content=[\'\"]([^\'\"]+)[\'\"]', html, re.I)
        if m: return m.group(1)
        m = re.search(r'<img[^>]+src=[\'\"]([^\'\"]+)[\'\"]', html, re.I)
        if m:
            src = m.group(1)
            if src.startswith("//"):
                parsed = urlparse(url); return f"{parsed.scheme}:{src}"
            if src.startswith("/"):
                parsed = urlparse(url); return f"{parsed.scheme}://{parsed.netloc}{src}"
            return src
        return ""
    except Exception:
        return ""

# ========================= Upstream & Gas Context =========================
PTT_CONTEXT = """
[‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó. ‚Äî ‡∏â‡∏ö‡∏±‡∏ö‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏á‡πà‡∏≤‡∏¢]

‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° value chain ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó. ‡∏î‡πâ‡∏≤‡∏ô‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:

1) ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Å‡πä‡∏≤‡∏ã‡πÅ‡∏•‡∏∞‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏î‡∏¥‡∏ö
   - ‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® (‡πÄ‡∏ä‡πà‡∏ô ‡∏≠‡πà‡∏≤‡∏ß‡πÑ‡∏ó‡∏¢)
   - ‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏Ç‡∏≠‡∏á‡πÄ‡∏´‡∏•‡∏ß (LNG) ‡∏ó‡∏µ‡πà‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏à‡∏≤‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®
   - ‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏¥‡∏ï (Upstream) ‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏î‡∏¢ PTTEP

2) ‡∏Å‡∏≤‡∏£‡∏Ç‡∏ô‡∏™‡πà‡∏á‡∏Å‡πä‡∏≤‡∏ã‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡πà‡∏≠
   - ‡∏Å‡πä‡∏≤‡∏ã‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ú‡∏•‡∏¥‡∏ï‡πÅ‡∏•‡∏∞‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ LNG ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡πà‡∏≠‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á ‡∏õ‡∏ï‡∏ó.
   - ‡∏°‡∏µ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡πÅ‡∏•‡∏∞‡∏à‡∏∏‡∏î‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡∏î‡∏π‡πÅ‡∏•‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏ô‡∏™‡πà‡∏á‡∏Å‡πä‡∏≤‡∏ã

3) ‡πÇ‡∏£‡∏á‡πÅ‡∏¢‡∏Å‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥
   - ‡πÇ‡∏£‡∏á‡πÅ‡∏¢‡∏Å‡∏Å‡πä‡∏≤‡∏ã‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏¢‡∏Å‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏≠‡∏≠‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÄ‡∏ä‡πà‡∏ô
     LPG, ‡∏Å‡πä‡∏≤‡∏ã‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°, feedstock ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ ‡πÅ‡∏•‡∏∞‡∏Å‡πä‡∏≤‡∏ã‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á
   - ‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏≤‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á‡πÉ‡∏´‡πâ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤

4) ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥
   - ‡πÇ‡∏£‡∏á‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ (‡πÉ‡∏ä‡πâ‡∏Å‡πä‡∏≤‡∏ã‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏Å ‡∏ó‡∏±‡πâ‡∏á SPP/IPP)
   - ‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏Ñ‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏Å‡πä‡∏≤‡∏ã‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡∏¥‡∏ö
   - ‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏Ñ‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô (‡πÉ‡∏ä‡πâ‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô/‡∏Å‡πä‡∏≤‡∏ã‡πÄ‡∏õ‡πá‡∏ô feedstock)
   - ‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡∏≤‡∏ô‡∏¢‡∏ô‡∏ï‡πå (NGV) ‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏Ñ‡∏Ç‡∏ô‡∏™‡πà‡∏á‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô
   - ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡πä‡∏≤‡∏ã‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡∏á‡πÄ‡∏´‡∏•‡∏ß‡∏à‡∏≤‡∏Å‡πÇ‡∏£‡∏á‡πÅ‡∏¢‡∏Å

5) ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó. ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏´‡πà‡∏ß‡∏á‡πÇ‡∏ã‡πà‡∏ô‡∏µ‡πâ
   - PTTEP      : ‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏¥‡∏ï‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏° (Upstream) ‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®
   - PTTLNG     : ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ ‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏£‡∏£‡∏π‡∏õ LNG
   - PTTGL / ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡πà‡∏≠‡∏Å‡πä‡∏≤‡∏ã : ‡∏Ç‡∏ô‡∏™‡πà‡∏á‡∏Å‡πä‡∏≤‡∏ã‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡πà‡∏≠‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏Ç‡πà‡∏≤‡∏¢‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥
   - PTTNGD     : ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°/‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á

[‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÉ‡∏ä‡πâ‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏ß‡πà‡∏≤ "‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ô‡∏µ‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"]

‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏Ç‡πà‡∏≤‡∏ß "‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç" ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
- ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à/‡∏ú‡∏•‡∏¥‡∏ï/‡∏õ‡∏£‡∏¥‡∏°‡∏≤‡∏ì‡∏™‡∏≥‡∏£‡∏≠‡∏á/‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏±‡∏ç‡∏ç‡∏≤ (PSC/‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô) ‡∏Ç‡∏≠‡∏á upstream
- ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏≤/‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤/‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å LNG, ‡∏Å‡∏≤‡∏£‡πÄ‡∏î‡∏¥‡∏ô‡πÄ‡∏£‡∏∑‡∏≠, ‡∏ó‡πà‡∏≤‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏£‡∏∑‡∏≠, FSRU, ‡πÇ‡∏£‡∏á‡πÅ‡∏¢‡∏Å‡∏Å‡πä‡∏≤‡∏ã, ‡∏ó‡πà‡∏≠‡∏™‡πà‡∏á‡∏Å‡πä‡∏≤‡∏ã
- ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏•‡∏∞‡∏™‡∏°‡∏î‡∏∏‡∏• supply‚Äìdemand ‡∏Ç‡∏≠‡∏á‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏î‡∏¥‡∏ö (Brent/WTI) ‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡πä‡∏≤‡∏ã/LNG (JKM, TTF, spot/contract) ‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏•‡∏Å
- ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢ ‡∏†‡∏≤‡∏©‡∏µ ‡∏Å‡∏é‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ê‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à Upstream ‡∏´‡∏£‡∏∑‡∏≠‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏Å‡πä‡∏≤‡∏ã‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó.
- ‡πÄ‡∏´‡∏ï‡∏∏‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á ‡πÄ‡∏´‡∏ï‡∏∏‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô ‡∏†‡∏±‡∏¢‡∏û‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏´‡∏ï‡∏∏‡∏†‡∏π‡∏°‡∏¥‡∏£‡∏±‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ supply ‡∏´‡∏≤‡∏¢‡πÑ‡∏õ ‡∏ä‡∏∞‡∏á‡∏±‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô‡∏û‡∏∏‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
- ‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô/‡∏î‡∏µ‡∏• M&A/FID/‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡πà‡∏≠‡∏Å‡πä‡∏≤‡∏ã/‡πÇ‡∏£‡∏á‡πÅ‡∏¢‡∏Å/‡∏Ñ‡∏•‡∏±‡∏á LNG/‡πÇ‡∏£‡∏á‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡πÉ‡∏´‡∏°‡πà ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ú‡∏•‡∏¥‡∏ï‡∏´‡∏£‡∏∑‡∏≠‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡πÉ‡∏ô‡∏ï‡∏•‡∏≤‡∏î

‡πÉ‡∏´‡πâ‡∏ï‡∏±‡∏î‡∏Ç‡πà‡∏≤‡∏ß‡∏≠‡∏≠‡∏Å ("‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà") ‡πÄ‡∏°‡∏∑‡πà‡∏≠:
- ‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î downstream, ‡πÇ‡∏õ‡∏£‡πÇ‡∏°‡∏ä‡∏±‡πà‡∏ô‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡∏£‡∏π‡∏õ, EV ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
  ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Å‡∏±‡∏ö supply‚Äìdemand ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏Å‡πä‡∏≤‡∏ã/‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó.
"""

# ========================= Gemini Wrapper =========================
def call_gemini(prompt, max_retries=MAX_RETRIES):
    global GEMINI_CALLS
    if GEMINI_CALLS >= GEMINI_DAILY_BUDGET:
        raise RuntimeError(f"‡∏ñ‡∏∂‡∏á‡∏á‡∏ö Gemini ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô‡πÅ‡∏•‡πâ‡∏ß ({GEMINI_CALLS}/{GEMINI_DAILY_BUDGET})")
    last_error = None
    for attempt in range(1, max_retries + 1):
        try:
            resp = model.generate_content(prompt)
            GEMINI_CALLS += 1
            return resp
        except Exception as e:
            err_str = str(e)
            if attempt < max_retries and any(x in err_str for x in ["429","exhausted","temporarily","unavailable","deadline","500","503"]):
                time.sleep(min(60, 5 * attempt))
                continue
            last_error = e
            if attempt < max_retries:
                time.sleep(3 * attempt)
            else:
                raise last_error
    raise last_error

# ===== Filter: ‡πÉ‡∏ä‡πà/‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà =====
def llm_ptt_subsidiary_impact_filter(news):
    prompt = f'''
{PTT_CONTEXT}

‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô "News Screener" ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó. ‡∏î‡πâ‡∏≤‡∏ô‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥

‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏°‡∏µ‡πÅ‡∏Ñ‡πà 2 ‡∏Ñ‡∏≥‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
- "‡πÉ‡∏ä‡πà"    = ‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏≤‡∏£‡∏∞‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö Upstream ‡∏´‡∏£‡∏∑‡∏≠‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏Å‡πä‡∏≤‡∏ã‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó.
- "‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà" = ‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô downstream/PR/‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÇ‡∏¢‡∏á‡∏°‡∏≤‡∏ñ‡∏∂‡∏á upstream/gas ‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô

‡∏Ç‡πà‡∏≤‡∏ß:
‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {news['title']}
‡∏™‡∏£‡∏∏‡∏õ: {news['summary']}
‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: {news.get('detail','')}

‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÄ‡∏î‡∏µ‡∏¢‡∏ß: "‡πÉ‡∏ä‡πà" ‡∏´‡∏£‡∏∑‡∏≠ "‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà"
'''
    try:
        resp = call_gemini(prompt)
        ans = (resp.text or "").strip().replace("\n", "")
        return ans.startswith("‡πÉ‡∏ä‡πà")
    except Exception as e:
        print("[ERROR] LLM Filter:", e)
        return False

# ===== Tag ‡∏Ç‡πà‡∏≤‡∏ß: ‡∏™‡∏£‡∏∏‡∏õ + ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó / ‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô / ‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ =====
def gemini_tag_news(news):
    schema = {
        "type": "object",
        "properties": {
            "summary": {"type": "string"},
            "impact_companies": {
                "type": "array",
                "items": {
                    "type": "string",
                    "enum": ["PTTEP", "PTTLNG", "PTTGL", "PTTNGD"]
                }
            },
            "topic_type": {
                "type": "string",
                "enum": [
                    "supply_disruption",
                    "price_move",
                    "policy",
                    "investment",
                    "geopolitics",
                    "other"
                ]
            },
            "region": {
                "type": "string",
                "enum": [
                    "global",
                    "asia",
                    "europe",
                    "middle_east",
                    "us",
                    "other"
                ]
            },
            "impact_reason": {"type": "string"}
        },
        "required": ["summary", "impact_companies", "topic_type", "region", "impact_reason"]
    }

    prompt = f"""
{PTT_CONTEXT}

‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: Analyst ‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó. (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥)
‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πà‡∏≤‡∏ß ‡πÅ‡∏•‡∏∞‡∏ï‡∏¥‡∏î‡πÅ‡∏ó‡πá‡∏Å" ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ï‡∏≤‡∏°‡∏´‡πà‡∏ß‡∏á‡πÇ‡∏ã‡πà‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏à‡∏≤‡∏Å
‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Å‡πä‡∏≤‡∏ã ‚Üí ‡∏£‡∏∞‡∏ö‡∏ö‡∏ó‡πà‡∏≠ ‚Üí ‡πÇ‡∏£‡∏á‡πÅ‡∏¢‡∏Å‡∏Å‡πä‡∏≤‡∏ã ‚Üí ‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡πÇ‡∏£‡∏á‡πÑ‡∏ü‡∏ü‡πâ‡∏≤/‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°/NGV ‡∏Ø‡∏•‡∏Ø

‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏Ç‡πà‡∏≤‡∏ß:
‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {news['title']}
‡∏™‡∏£‡∏∏‡∏õ (‡∏à‡∏≤‡∏Å RSS): {news['summary']}
‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: {news.get('detail','')}

‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡∏ï‡∏≤‡∏° schema ‡∏ô‡∏µ‡πâ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{json.dumps(schema, ensure_ascii=False)}

‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ field:
- summary:
  ‚Ä¢ ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÅ‡∏ï‡πà‡πÉ‡∏´‡πâ‡∏ö‡∏≠‡∏Å‡∏ä‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£ ‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡πä‡∏≤‡∏ã/‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô/‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£
- impact_companies:
  ‚Ä¢ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å ["PTTEP","PTTLNG","PTTGL","PTTNGD"]
  ‚Ä¢ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏î‡πâ 0‚Äì2 ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÉ‡∏î‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô [] (array ‡∏ß‡πà‡∏≤‡∏á)
- topic_type:
  ‚Ä¢ supply_disruption = ‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏ä‡∏∞‡∏á‡∏±‡∏Å/‡∏•‡∏î‡∏•‡∏á‡∏Ç‡∏≠‡∏á supply (‡∏ó‡πà‡∏≠, ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ú‡∏•‡∏¥‡∏ï, ‡πÇ‡∏£‡∏á‡πÅ‡∏¢‡∏Å, LNG, ‡∏Ñ‡∏•‡∏±‡∏á ‡∏Ø‡∏•‡∏Ø)
  ‚Ä¢ price_move        = ‡∏Ç‡πà‡∏≤‡∏ß‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô/‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Å‡πä‡∏≤‡∏ã/‡∏£‡∏≤‡∏Ñ‡∏≤ LNG ‡∏Ç‡∏¢‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏á‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏ô‡∏±‡∏¢
  ‚Ä¢ policy            = ‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏£‡∏±‡∏ê, ‡∏†‡∏≤‡∏©‡∏µ, ‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢, ‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏î‡∏π‡πÅ‡∏•‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö Upstream/Gas
  ‚Ä¢ investment        = ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô, FID, M&A, ‡∏Å‡∏≤‡∏£‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ú‡∏•‡∏¥‡∏ï, ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡∏°‡πà
  ‚Ä¢ geopolitics       = ‡∏†‡∏π‡∏°‡∏¥‡∏£‡∏±‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå, ‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°, ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏±‡∏î‡πÅ‡∏¢‡πâ‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô
  ‚Ä¢ other             = ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Upstream/Gas ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏°‡∏ß‡∏î‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô
- region:
  ‚Ä¢ global, asia, europe, middle_east, us, other
  ‚Ä¢ ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å region ‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏Ç‡πà‡∏≤‡∏ß
- impact_reason:
  ‚Ä¢ ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ 1‚Äì3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏ß‡πà‡∏≤ ‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÑ‡∏õ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏´‡πà‡∏ß‡∏á‡πÇ‡∏ã‡πà‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó. ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£
  ‚Ä¢ ‡∏ñ‡πâ‡∏≤ impact_companies ‡πÄ‡∏õ‡πá‡∏ô [] ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ï‡∏•‡∏≤‡∏î/‡∏£‡∏≤‡∏Ñ‡∏≤

‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏∑‡πà‡∏ô‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å JSON ‡∏ï‡∏≤‡∏° schema ‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô
"""

    try:
        resp = call_gemini(prompt)
        raw = (resp.text or "").strip()

        if raw.startswith("```"):
            raw = re.sub(r"^```(json)?", "", raw).strip()
            raw = re.sub(r"```$", "", raw).strip()

        data = json.loads(raw)
        return data

    except Exception as e:
        print("[WARN] JSON parse fail in gemini_tag_news:", e)
        return {
            "summary": news.get("summary") or news.get("title") or "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏î‡πâ",
            "impact_companies": [],
            "topic_type": "other",
            "region": "other",
            "impact_reason": "fallback ‚Äì ‡πÉ‡∏ä‡πâ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å RSS ‡πÅ‡∏ó‡∏ô"
        }

# ========================= Logic =========================
def is_ptt_related_from_output(impact_companies) -> bool:
    return bool(impact_companies)

def fetch_news_9pm_to_6am():
    now_local = datetime.now(bangkok_tz)
    start_time = (now_local - timedelta(days=1)).replace(hour=21, minute=0, second=0, microsecond=0)
    end_time = now_local.replace(hour=6, minute=0, second=0, microsecond=0)

    all_news = []
    for _, info in news_sources.items():
        try:
            feed = feedparser.parse(info["url"])
            for entry in feed.entries:
                pub_str = getattr(entry, "published", None) or getattr(entry, "updated", None)
                if not pub_str and getattr(entry, "published_parsed", None):
                    t = entry.published_parsed
                    pub_dt = datetime(*t[:6], tzinfo=pytz.UTC).astimezone(bangkok_tz)
                else:
                    if not pub_str:
                        continue
                    pub_dt = dateutil_parser.parse(pub_str)
                    if pub_dt.tzinfo is None:
                        pub_dt = pytz.UTC.localize(pub_dt)
                    pub_dt = pub_dt.astimezone(bangkok_tz)

                if not (start_time <= pub_dt <= end_time):
                    continue

                summary = getattr(entry, "summary", "") or getattr(entry, "description", "")
                link = getattr(entry, "link", "")
                title = getattr(entry, "title", "-")

                all_news.append({
                    "site": info["site"],
                    "category": info["category"],
                    "title": title,
                    "summary": summary,
                    "link": link,
                    "published": pub_dt,
                    "date": pub_dt.strftime("%d/%m/%Y %H:%M"),
                })
        except Exception as e:
            print(f"[WARN] ‡∏≠‡πà‡∏≤‡∏ô‡∏ü‡∏µ‡∏î {info['site']} ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}")

    # de-dup by normalized URL
    seen, uniq = set(), []
    for n in all_news:
        key = _normalize_link(n.get("link", ""))
        if key and key not in seen:
            seen.add(key)
            uniq.append(n)
    return uniq

# --------- Coverage-first selection ----------
KEY_COMPANIES = ["PTTEP", "PTTLNG", "PTTGL", "PTTNGD"]
KEY_TOPICS = ["supply_disruption", "price_move", "policy", "investment", "geopolitics"]

def select_news_coverage_first(news_list, max_items=10):
    """
    ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πà‡∏≤‡∏ß/‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÇ‡∏î‡∏¢‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°:
    1) ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ
    2) ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏°‡∏µ‡∏ó‡∏∏‡∏Å topic_type ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏ó‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ
    3) ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏ï‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà‡∏™‡∏∏‡∏î (published ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô)
    """
    if not news_list:
        return []

    sorted_news = sorted(news_list, key=lambda n: n.get("published"), reverse=True)

    selected = []
    used_ids = set()

    def _add_if_not_selected(candidate):
        key = _normalize_link(candidate.get("link", "")) or id(candidate)
        if key in used_ids:
            return False
        if len(selected) >= max_items:
            return False
        selected.append(candidate)
        used_ids.add(key)
        return True

    # ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà 1: ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó
    for comp in KEY_COMPANIES:
        if len(selected) >= max_items:
            break
        for n in sorted_news:
            companies = n.get("ptt_companies") or []
            if comp in companies:
                if _add_if_not_selected(n):
                    break

    # ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà 2: ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° topic_type
    for topic in KEY_TOPICS:
        if len(selected) >= max_items:
            break
        if any((x.get("topic_type") == topic) for x in selected):
            continue
        for n in sorted_news:
            if n.get("topic_type") == topic:
                if _add_if_not_selected(n):
                    break

    # ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà 3: ‡πÄ‡∏ï‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà‡∏™‡∏∏‡∏î
    for n in sorted_news:
        if len(selected) >= max_items:
            break
        _add_if_not_selected(n)

    return selected

# --------- Grouping ‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡∏≤‡∏° topic + region ----------
def group_related_news(news_list, min_group_size=3):
    """
    ‡∏£‡∏±‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà tag ‡πÅ‡∏•‡πâ‡∏ß (‡∏°‡∏µ topic_type, region)
    ‡∏Ñ‡∏∑‡∏ô list ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á:
      - single ‡∏Ç‡πà‡∏≤‡∏ß‡∏õ‡∏Å‡∏ï‡∏¥ (dict ‡πÄ‡∏î‡∏¥‡∏°)
      - group ‡∏Ç‡πà‡∏≤‡∏ß (dict ‡πÉ‡∏´‡∏°‡πà is_group=True ‡πÅ‡∏•‡∏∞‡∏°‡∏µ news_items ‡πÄ‡∏õ‡πá‡∏ô list ‡∏Ç‡πà‡∏≤‡∏ß‡∏¢‡πà‡∏≠‡∏¢)
    """
    buckets = {}
    for n in news_list:
        key = (n.get("topic_type", "other"), n.get("region", "other"))
        buckets.setdefault(key, []).append(n)

    grouped_items = []

    for (topic, region), items in buckets.items():
        if len(items) >= min_group_size:
            all_companies = []
            for it in items:
                all_companies.extend(it.get("ptt_companies") or [])
            all_companies = list(dict.fromkeys(all_companies))

            items_sorted = sorted(items, key=lambda x: x.get("published"), reverse=True)
            anchor = items_sorted[0]

            group_obj = {
                "is_group": True,
                "topic_type": topic,
                "region": region,
                "ptt_companies": all_companies,
                "news_items": items_sorted,

                "title": anchor.get("title", "-"),
                "site": "‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß",
                "category": anchor.get("category", ""),
                "date": anchor.get("date", ""),
                "published": anchor.get("published"),
                "link": anchor.get("link", ""),
            }
            grouped_items.append(group_obj)
        else:
            grouped_items.extend(items)

    return grouped_items

def gemini_summarize_group(group):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á meta-summary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß (‡πÄ‡∏ä‡πà‡∏ô geopolitics + middle_east ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡πà‡∏≤‡∏ß)
    """
    items = group.get("news_items", [])
    if not items:
        return {
            "summary": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°",
            "impact_reason": "-"
        }

    lines = []
    for idx, n in enumerate(items, 1):
        line = f"{idx}. {n.get('title','-')} ‚Äî {n.get('summary','')}"
        lines.append(line)
    news_block = "\n".join(lines)

    prompt = f"""
{PTT_CONTEXT}

‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: Analyst ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡∏∏‡∏õ "‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°" ‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πà‡∏≤‡∏ß‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î‡∏ñ‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
‡∏à‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå: ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô bubble ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏ß‡πà‡∏≤ ‡πÄ‡∏Å‡∏¥‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏ô‡∏µ‡πâ ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡∏¢‡πà‡∏≠‡∏¢

‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß (‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡πà‡∏≠‡∏¢):
{news_block}

‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö:
{{
  "summary": "<‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏° 3‚Äì5 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ>",
  "impact_reason": "<‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏ß‡πà‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó. ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£ ‡πÇ‡∏î‡∏¢‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö upstream/gas value chain>"
}}

‡∏´‡πâ‡∏≤‡∏°‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏≠‡∏∑‡πà‡∏ô ‡∏ô‡∏≠‡∏Å‡∏à‡∏≤‡∏Å JSON ‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô
"""

    try:
        resp = call_gemini(prompt)
        raw = (resp.text or "").strip()
        if raw.startswith("```"):
            raw = re.sub(r"^```(json)?", "", raw).strip()
            raw = re.sub(r"```$", "", raw).strip()
        data = json.loads(raw)
        return data
    except Exception as e:
        print("[WARN] JSON parse fail in gemini_summarize_group:", e)
        return {
            "summary": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏î‡πâ",
            "impact_reason": "-"
        }

# --------- Labels ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Flex ---------
TOPIC_LABELS_TH = {
    "supply_disruption": "Supply ‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á/‡∏•‡∏î‡∏•‡∏á",
    "price_move": "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô/‡∏Å‡πä‡∏≤‡∏ã‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô",
    "policy": "‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢/‡∏Å‡∏é‡∏´‡∏°‡∏≤‡∏¢",
    "investment": "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô/M&A",
    "geopolitics": "‡∏†‡∏π‡∏°‡∏¥‡∏£‡∏±‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå/‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏°",
    "other": "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Upstream/‡∏Å‡πä‡∏≤‡∏ã",
}
REGION_LABELS_TH = {
    "global": "Global",
    "asia": "Asia",
    "europe": "Europe",
    "middle_east": "Middle East",
    "us": "US",
    "other": "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ",
}

def create_flex_message(news_items):
    now_thai = datetime.now(bangkok_tz).strftime("%d/%m/%Y")

    def join_companies(codes):
        codes = codes or []
        return ", ".join(codes) if codes else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏∞‡∏ö‡∏∏"

    bubbles = []
    for item in news_items:
        img = item.get("image") or DEFAULT_ICON_URL
        if not (str(img).startswith("http://") or str(img).startswith("https://")):
            img = DEFAULT_ICON_URL

        topic_key = item.get("topic_type", "other")
        region_key = item.get("region", "other")
        topic_label = TOPIC_LABELS_TH.get(topic_key, "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ")
        region_label = REGION_LABELS_TH.get(region_key, "‡∏≠‡∏∑‡πà‡∏ô ‡πÜ")

        impact_line = {
            "type": "text",
            "text": f"‡∏Å‡∏£‡∏∞‡∏ó‡∏ö: {join_companies(item.get('ptt_companies'))}",
            "size": "xs",
            "color": "#000000",
            "weight": "bold",
            "wrap": True,
            "margin": "sm"
        }

        meta_line = {
            "type": "text",
            "text": f"‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó: {topic_label} | ‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ: {region_label}",
            "size": "xs",
            "color": "#555555",
            "wrap": True,
            "margin": "sm"
        }

        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß ‚Üí ‡πÅ‡∏™‡∏î‡∏á list ‡∏Ç‡πà‡∏≤‡∏ß‡∏¢‡πà‡∏≠‡∏¢
        group_sublist_box = None
        if item.get("is_group"):
            sub_items = item.get("news_items", [])[:5]
            sub_lines = []
            for sub in sub_items:
                line = f"‚Ä¢ [{sub.get('site','')}] {sub.get('title','-')}"
                sub_lines.append(line)
            sub_text = "\n".join(sub_lines) if sub_lines else "-"

            group_sublist_box = {
                "type": "box",
                "layout": "vertical",
                "margin": "md",
                "contents": [
                    {
                        "type": "text",
                        "text": "‡∏Ç‡πà‡∏≤‡∏ß‡∏¢‡πà‡∏≠‡∏¢‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ:",
                        "size": "xs",
                        "weight": "bold",
                        "color": "#000000",
                        "wrap": True
                    },
                    {
                        "type": "text",
                        "text": sub_text,
                        "size": "xs",
                        "color": "#444444",
                        "wrap": True
                    }
                ]
            }

        title_text = item.get("title", "-")
        if item.get("is_group"):
            count_sub = len(item.get("news_items", []))
            title_text = f"{topic_label} ({region_label}) ‚Äì {count_sub} ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç"

        body_contents = [
            {
                "type": "text",
                "text": title_text,
                "weight": "bold",
                "size": "lg",
                "wrap": True,
                "color": "#111111"
            },
            {
                "type": "box",
                "layout": "horizontal",
                "margin": "sm",
                "contents": [
                    {
                        "type": "text",
                        "text": f"üóì {item.get('date','-')}",
                        "size": "xs",
                        "color": "#aaaaaa",
                        "flex": 5
                    },
                    {
                        "type": "text",
                        "text": f"üìå {item.get('category','')}",
                        "size": "xs",
                        "color": "#888888",
                        "align": "end",
                        "flex": 5
                    }
                ]
            },
            {
                "type": "text",
                "text": f"üåç {item.get('site','')}",
                "size": "xs",
                "color": "#448AFF",
                "margin": "sm"
            },
            impact_line,
            meta_line,
            {
                "type": "text",
                "text": item.get("gemini_summary") or "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πà‡∏≤‡∏ß",
                "size": "md",
                "wrap": True,
                "margin": "md",
                "color": "#1A237E",
                "weight": "bold"
            },
            {
                "type": "box",
                "layout": "vertical",
                "margin": "lg",
                "contents": [
                    {
                        "type": "text",
                        "text": "‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡∏Å‡∏•‡∏∏‡πà‡∏° ‡∏õ‡∏ï‡∏ó.",
                        "weight": "bold",
                        "size": "lg",
                        "color": "#D32F2F"
                    },
                    {
                        "type": "text",
                        "text": (item.get("gemini_reason") or "-"),
                        "size": "md",
                        "wrap": True,
                        "color": "#C62828",
                        "weight": "bold"
                    },
                ]
            }
        ]

        if group_sublist_box:
            body_contents.append(group_sublist_box)

        bubble = {
            "type": "bubble",
            "size": "mega",
            "hero": {
                "type": "image",
                "url": img,
                "size": "full",
                "aspectRatio": "16:9",
                "aspectMode": "cover"
            },
            "body": {
                "type": "box",
                "layout": "vertical",
                "spacing": "md",
                "contents": body_contents
            },
            "footer": {
                "type": "box",
                "layout": "vertical",
                "spacing": "sm",
                "contents": [
                    {
                        "type": "text",
                        "text": "‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö",
                        "size": "xs",
                        "color": "#FF0000",
                        "wrap": True,
                        "margin": "md"
                    },
                    {
                        "type": "button",
                        "style": "primary",
                        "color": "#1DB446",
                        "action": {
                            "type": "uri",
                            "label": "‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡πà‡∏≠",
                            "uri": item.get("link", "#")
                        }
                    }
                ]
            }
        }
        bubbles.append(bubble)

    carousels = []
    for i in range(0, len(bubbles), 10):
        carousels.append({
            "type": "flex",
            "altText": f"‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö ‡∏õ‡∏ï‡∏ó. {now_thai}",
            "contents": {
                "type": "carousel",
                "contents": bubbles[i:i+10]
            }
        })
    return carousels

def broadcast_flex_message(access_token, flex_carousels):
    url = 'https://api.line.me/v2/bot/message/broadcast'
    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {access_token}"}
    for idx, carousel in enumerate(flex_carousels, 1):
        payload = {"messages": [carousel]}
        if DRY_RUN:
            print(f"[DRY_RUN] Carousel #{idx}: {json.dumps(payload)[:500]}...")
            continue
        try:
            resp = S.post(url, headers=headers, json=payload, timeout=TIMEOUT)
            print(f"Broadcast #{idx} status:", resp.status_code, getattr(resp, "text", ""))
            if resp.status_code >= 300:
                break
            time.sleep(1.2)
        except Exception as e:
            print("[LINE ERROR]", e)
            break

# ========================= MAIN =========================
def main():
    all_news = fetch_news_9pm_to_6am()
    print(f"‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏ä‡πà‡∏ß‡∏á 21:00 ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô ‡∏ñ‡∏∂‡∏á 06:00 ‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ: {len(all_news)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
    if not all_news:
        print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß")
        return

    SLEEP_MIN, SLEEP_MAX = SLEEP_BETWEEN_CALLS

    # 1) Filter: ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö Upstream/Gas
    filtered_news = []
    for news in all_news:
        news['detail'] = news['title'] if len((news.get('summary') or '')) < 50 else ''
        if llm_ptt_subsidiary_impact_filter(news):
            filtered_news.append(news)
        time.sleep(random.uniform(SLEEP_MIN, SLEEP_MAX))

    print(f"‡∏Ç‡πà‡∏≤‡∏ß‡∏ú‡πà‡∏≤‡∏ô‡∏ü‡∏¥‡∏•‡πÄ‡∏ï‡∏≠‡∏£‡πå (‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á Upstream/Gas): {len(filtered_news)} ‡∏Ç‡πà‡∏≤‡∏ß")
    if not filtered_news:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á")
        return

    # 2) Tagging: ‡∏™‡∏£‡∏∏‡∏õ + tag ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó/‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô/‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ
    tagged_news = []
    print(f"‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ Gemini ‡∏ï‡∏¥‡∏î‡πÅ‡∏ó‡πá‡∏Å {len(filtered_news)} ‡∏Ç‡πà‡∏≤‡∏ß")
    for news in filtered_news:
        tag = gemini_tag_news(news)

        news['gemini_summary'] = _normalize_colons(tag.get('summary', '')).strip() or '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πà‡∏≤‡∏ß'
        companies = [c for c in (tag.get('impact_companies') or []) if c in {"PTTEP", "PTTLNG", "PTTGL", "PTTNGD"}]
        news['ptt_companies'] = list(dict.fromkeys(companies))
        news['topic_type'] = tag.get('topic_type', 'other')
        news['region'] = tag.get('region', 'other')
        news['gemini_reason'] = _polish_impact_text(tag.get('impact_reason', '').strip()) or '-'

        if is_ptt_related_from_output(news['ptt_companies']):
            tagged_news.append(news)

        time.sleep(random.uniform(SLEEP_MIN, SLEEP_MAX))

    print(f"‡πÉ‡∏ä‡πâ Gemini ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß: {GEMINI_CALLS}/{GEMINI_DAILY_BUDGET} calls")
    if not tagged_news:
        print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏ú‡∏π‡∏Å‡∏Å‡∏±‡∏ö‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠ PTT ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á")
        return

    # 3) Grouping: ‡∏¢‡∏∏‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà topic+region ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ >= 3 ‡∏Ç‡πà‡∏≤‡∏ß)
    collapsed_list = group_related_news(tagged_news, min_group_size=3)

    # 4) ‡∏ó‡∏≥ meta-summary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß
    for item in collapsed_list:
        if item.get("is_group"):
            data = gemini_summarize_group(item)
            item["gemini_summary"] = _normalize_colons(data.get("summary", "")).strip()
            item["gemini_reason"] = _polish_impact_text(data.get("impact_reason", "").strip() or "-")

    # 5) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡∏∏‡∏î‡∏Ç‡πà‡∏≤‡∏ß/‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÅ‡∏ö‡∏ö coverage-first (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 10 bubble)
    top_news = select_news_coverage_first(collapsed_list, max_items=10)

    sent_links = load_sent_links_today_yesterday()
    top_news_to_send = [n for n in top_news if _normalize_link(n.get('link', '')) not in sent_links]
    if not top_news_to_send:
        print("‡∏Ç‡πà‡∏≤‡∏ß‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ/‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô‡∏™‡πà‡∏á‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡πâ‡∏ß")
        return

    # 6) ‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏Ç‡πà‡∏≤‡∏ß
    for item in top_news_to_send:
        img = fetch_article_image(item.get("link", "")) or ""
        if not (str(img).startswith("http://") or str(img).startswith("https://")):
            img = DEFAULT_ICON_URL
        item["image"] = img

    # 7) ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ LINE
    carousels = create_flex_message(top_news_to_send)
    broadcast_flex_message(LINE_CHANNEL_ACCESS_TOKEN, carousels)
    save_sent_links([n.get("link", "") for n in top_news_to_send])
    print("‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô.")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print("[ERROR]", e)
