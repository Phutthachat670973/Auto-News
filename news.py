# -*- coding: utf-8 -*-
"""
Enhanced News Aggregator with WTI Futures (EIA API Only)
‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏£‡∏≤‡∏Ñ‡∏≤ WTI Futures ‡∏à‡∏≤‡∏Å EIA.gov
"""

import os
import re
import json
import time
import hashlib
from datetime import datetime, timedelta
from urllib.parse import urlparse, parse_qs, unquote
from difflib import SequenceMatcher
from typing import List, Set, Tuple, Optional, Dict

import requests
import feedparser
import pytz
from dateutil import parser as dateutil_parser
from news_examples import get_few_shot_examples
try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

# =============================================================================
# ENV / CONFIG
# =============================================================================
TZ = pytz.timezone(os.getenv("TZ", "Asia/Bangkok"))

LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "").strip()
if not LINE_CHANNEL_ACCESS_TOKEN:
    raise RuntimeError("Missing LINE_CHANNEL_ACCESS_TOKEN")

# Groq Configuration
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "").strip()
GROQ_MODEL = os.getenv("GROQ_MODEL", "llama-3.1-8b-instant").strip()
GROQ_ENDPOINT = os.getenv("GROQ_ENDPOINT", "https://api.groq.com/openai/v1/chat/completions").strip()
USE_LLM_SUMMARY = os.getenv("USE_LLM_SUMMARY", "1").strip().lower() in ["1", "true", "yes", "y"]

# EIA API (Required!)
EIA_API_KEY = os.getenv("EIA_API_KEY", "").strip()
if not EIA_API_KEY:
    raise RuntimeError("Missing EIA_API_KEY - Get one from https://www.eia.gov/opendata/")

WINDOW_HOURS = int(os.getenv("WINDOW_HOURS", "48"))
MAX_PER_FEED = int(os.getenv("MAX_PER_FEED", "30"))
DRY_RUN = os.getenv("DRY_RUN", "0").strip().lower() in ["1", "true", "yes", "y"]
BUBBLES_PER_CAROUSEL = int(os.getenv("BUBBLES_PER_CAROUSEL", "10"))

# Debug mode
DEBUG_FILTERING = os.getenv("DEBUG_FILTERING", "1").strip().lower() in ["1", "true", "yes", "y"]

# Allowed news sources
ALLOWED_NEWS_SOURCES = os.getenv("ALLOWED_NEWS_SOURCES", "").strip()
if ALLOWED_NEWS_SOURCES:
    ALLOWED_NEWS_SOURCES_LIST = [s.strip().lower() for s in ALLOWED_NEWS_SOURCES.split(",") if s.strip()]
    print(f"[CONFIG] ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏ß‡πá‡∏ö‡∏Ç‡πà‡∏≤‡∏ß: {ALLOWED_NEWS_SOURCES_LIST}")
else:
    ALLOWED_NEWS_SOURCES_LIST = []
    print("[CONFIG] ‡∏£‡∏±‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡∏Ç‡πà‡∏≤‡∏ß")

# Sent links tracking
SENT_DIR = os.getenv("SENT_DIR", "sent_links")
os.makedirs(SENT_DIR, exist_ok=True)

# =============================================================================
# PROJECT DATABASE
# =============================================================================
PROJECTS_BY_COUNTRY = {
    "Thailand": [
        "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏µ 1/61", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏µ 2/61", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå", "Arthit",
        "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏™ 1", "S1", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô 4", "Contract 4",
        "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏µ‡∏ó‡∏µ‡∏ó‡∏µ‡∏≠‡∏µ‡∏û‡∏µ 1", "PTTEP 1", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏µ 6/27",
        "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏≠‡∏• 22/43", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏µ 5", "E5",
        "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏µ 4/43", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏¥‡∏ô‡∏†‡∏π‡∏Æ‡πà‡∏≠‡∏°", "Sinphuhorm",
        "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏µ 8/32", "B8/32", "9A", "9‡πÄ‡∏≠",
        "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏µ 4/48", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏µ 12/48",
        "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏µ 1/65", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏µ 3/65",
        "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏≠‡∏• 53/43", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏≠‡∏• 54/43"
    ],
    "Myanmar": ["‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ã‡∏≠‡∏ï‡∏¥‡∏Å‡πâ‡∏≤", "Zawtika", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏¢‡∏≤‡∏î‡∏≤‡∏ô‡∏≤", "Yadana", "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏µ‡∏¢‡∏ô‡∏°‡∏≤ ‡πÄ‡∏≠‡πá‡∏° 3", "Myanmar M3"],
    "Malaysia": ["Malaysia SK309", "SK309", "Malaysia SK311", "SK311", "Malaysia Block H", "Block H"],
    "Vietnam": ["‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏° 16-1", "Vietnam 16-1", "16-1", "Block B", "48/95"],
    "Indonesia": ["‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≤‡∏ó‡∏π‡∏ô‡πà‡∏≤ ‡∏ã‡∏µ ‡πÄ‡∏≠", "Natuna Sea A"],
    "Kazakhstan": ["‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∏‡∏á‡∏Å‡∏≤", "Dunga"],
    "Oman": ["Oman Block 61", "Block 61", "Oman Block 6", "PDO"],
    "UAE": ["Abu Dhabi Offshore 1", "Abu Dhabi Offshore 2", "Abu Dhabi Offshore 3"],
}
# =============================================================================
# ENHANCED DEDUPLICATION SYSTEM (FIXED - Less Aggressive)
# =============================================================================
class EnhancedDeduplication:
    """‡∏£‡∏∞‡∏ö‡∏ö‡∏Å‡∏±‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏ã‡πâ‡∏≥‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡∏°‡πà - ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î"""
    
    THAI_STOP_WORDS = {
        '‡∏ó‡∏µ‡πà', '‡πÉ‡∏ô', '‡∏à‡∏≤‡∏Å', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏Å‡∏≤‡∏£', '‡πÅ‡∏•‡∏∞', '‡∏Ç‡∏≠‡∏á', '‡πÑ‡∏î‡πâ', '‡∏°‡∏µ', '‡∏ß‡πà‡∏≤',
        '‡∏Å‡∏±‡∏ö', '‡πÇ‡∏î‡∏¢', '‡πÉ‡∏´‡πâ', '‡πÅ‡∏•‡πâ‡∏ß', '‡πÑ‡∏õ', '‡∏°‡∏≤', '‡∏≠‡∏¢‡∏π‡πà', '‡∏¢‡∏±‡∏á', '‡∏Ñ‡∏∑‡∏≠', '‡∏ñ‡∏∂‡∏á',
        '‡∏ô‡∏µ‡πâ', '‡∏ô‡∏±‡πâ‡∏ô', '‡∏ã‡∏∂‡πà‡∏á', '‡πÄ‡∏û‡∏∑‡πà‡∏≠', '‡πÅ‡∏ï‡πà', '‡∏ñ‡πâ‡∏≤', '‡∏à‡∏∞', '‡∏Å‡πá', '‡πÑ‡∏°‡πà', '‡∏Ç‡∏∂‡πâ‡∏ô'
    }
    
    ENGLISH_STOP_WORDS = {
        'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
        'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',
        'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would',
        'could', 'should', 'may', 'might', 'can', 'this', 'that', 'these',
        'those', 'it', 'its'
    }
    
    GROUPING_KEYWORDS = {
        'pttep', '‡∏õ‡∏ï‡∏ó.', 'murphy', 'shell', 'chevron', 'exxon', 'total',
        '‡πÅ‡∏ö‡∏£‡πá‡∏Ñ ‡∏≠‡∏¥‡∏•‡∏™‡πå', 'black hills', '‡∏ö‡∏≤‡∏á‡∏à‡∏≤‡∏Å', 'irpc', 'top',
        'appraisal', 'discovery', 'drilling', 'exploration', 'production',
        'field', 'block', 'concession', '‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô', '‡πÅ‡∏´‡∏•‡πà‡∏á', '‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£',
        'lng', 'terminal', 'pipeline', 'refinery', 'power plant',
        '‡πÇ‡∏£‡∏á‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', '‡∏ó‡πà‡∏≠‡∏™‡πà‡∏á', '‡∏Ñ‡∏•‡∏±‡∏á‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô',
        'price', 'market', 'trading', '‡∏£‡∏≤‡∏Ñ‡∏≤', '‡∏ï‡∏•‡∏≤‡∏î',
        'oil', 'gas', 'electricity', 'renewable', 'solar', 'wind',
        '‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô', '‡∏Å‡πä‡∏≤‡∏ã', '‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏î‡πÅ‡∏ó‡∏ô',
        'investment', 'deal', 'agreement', 'contract', 'acquisition',
        '‡∏•‡∏á‡∏ó‡∏∏‡∏ô', '‡∏™‡∏±‡∏ç‡∏ç‡∏≤', '‡∏ã‡∏∑‡πâ‡∏≠', '‡∏Ç‡∏≤‡∏¢'
    }
    
    def __init__(self):
        self.seen_urls: Set[str] = set()
        self.seen_fingerprints: Set[str] = set()
        self.processed_items: List[dict] = []
        self.title_cache: List[Tuple[str, str]] = []
    
    def normalize_text(self, text: str) -> str:
        """Normalize text ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö"""
        if not text:
            return ""
        
        text = text.lower()
        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)
        text = re.sub(r'[^\w\s]', ' ', text)
        text = re.sub(r'\d+', '', text)
        text = ' '.join(text.split())
        
        words = text.split()
        filtered_words = [
            w for w in words 
            if w not in self.THAI_STOP_WORDS 
            and w not in self.ENGLISH_STOP_WORDS
            and len(w) > 1
        ]
        
        return ' '.join(filtered_words)
    
    def extract_keywords(self, text: str) -> Set[str]:
        """‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        text_lower = text.lower()
        found_keywords = set()
        
        for keyword in self.GROUPING_KEYWORDS:
            if keyword in text_lower:
                found_keywords.add(keyword)
        
        return found_keywords
    
    def create_content_fingerprint(self, item: dict) -> str:
        """
        ‡∏™‡∏£‡πâ‡∏≤‡∏á fingerprint ‡∏à‡∏≤‡∏Å‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß
        
        ‚úÖ FIX: ‡πÉ‡∏ä‡πâ title ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î + ‡∏ï‡∏±‡∏î‡πÄ‡∏•‡∏Ç‡∏≠‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡∏ö‡∏à‡∏∞‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô
        """
        title = self.normalize_text(item.get('title', ''))
        
        # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°: ‡∏ï‡∏±‡∏î source ‡πÅ‡∏•‡∏∞‡πÄ‡∏ß‡∏•‡∏≤‡∏≠‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
        # ‡πÄ‡∏ä‡πà‡∏ô "9 ‡∏´‡∏∏‡πâ‡∏ô‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏Å‡∏≠‡∏î‡∏Ñ‡∏≠‡∏ö‡∏ß‡∏Å SPRC-OR ‡∏ô‡πà‡∏≤‡∏Ñ‡∏∏‡πâ‡∏° 3.91%" ‡∏à‡∏≤‡∏Å 2 ‡πÅ‡∏´‡∏•‡πà‡∏á
        title_clean = re.sub(r'\s+', ' ', title).strip()
        
        country = item.get('country', '')
        keywords = self.extract_keywords(f"{item.get('title', '')} {item.get('summary', '')}")
        keywords_str = '|'.join(sorted(keywords))
        
        # ‡πÉ‡∏ä‡πâ title ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ï‡∏±‡∏î‡πÄ‡∏´‡∏•‡∏∑‡∏≠ 100 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
        content = f"{title_clean}|{country}|{keywords_str}"
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"""
        norm1 = self.normalize_text(text1)
        norm2 = self.normalize_text(text2)
        
        if not norm1 or not norm2:
            return 0.0
        
        return SequenceMatcher(None, norm1, norm2).ratio()
    
    def is_duplicate_content(self, item: dict) -> Tuple[bool, Optional[str]]:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏ã‡πâ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà (‡∏õ‡∏£‡∏±‡∏ö‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î)
        
        FIXED: ‡∏•‡∏î‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á
        - Title similarity: 0.75 -> 0.90 (‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 90%)
        - Keyword matching: 0.70 -> 0.85 (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô 85%+)
        - Time window: 48 -> 24 ‡∏ä‡∏°. (‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤)
        """
        url = item.get('canon_url') or item.get('url', '')
        if self.is_duplicate_url(url):
            return True, "URL ‡∏ã‡πâ‡∏≥"
        
        # ‚úÖ FIX: ‡πÄ‡∏ä‡πá‡∏Ñ Exact Title Match ‡∏Å‡πà‡∏≠‡∏ô (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á)
        title = item.get('title', '')
        for existing in self.processed_items:
            existing_title = existing.get('title', '')
            # ‡∏ñ‡πâ‡∏≤ title ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô 100% = ‡∏ã‡πâ‡∏≥‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô
            if title == existing_title:
                return True, "Title ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£"
            
            # ‡∏ñ‡πâ‡∏≤ title ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 95% (‡πÅ‡∏ó‡∏ö‡∏à‡∏∞‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô)
            similarity = self.calculate_similarity(title, existing_title)
            if similarity > 0.95:
                return True, f"Title ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥ ({similarity:.1%})"
        
        fingerprint = self.create_content_fingerprint(item)
        if fingerprint in self.seen_fingerprints:
            return True, "Fingerprint ‡∏ã‡πâ‡∏≥ (‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)"
        self.seen_fingerprints.add(fingerprint)
        
        title = item.get('title', '')
        
        # ‚úÖ FIX 1: ‡∏¢‡∏Å‡πÄ‡∏Å‡∏ì‡∏ë‡πå title similarity ‡∏à‡∏≤‡∏Å 0.75 -> 0.90
        for cached_norm_title, cached_orig_title in self.title_cache:
            similarity = self.calculate_similarity(title, cached_norm_title)
            
            # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å 0.75 ‡πÄ‡∏õ‡πá‡∏ô 0.90 (‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 90%)
            if similarity > 0.90:
                return True, f"Title ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≥ ({similarity:.1%})"
            
            # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å 0.65 ‡πÄ‡∏õ‡πá‡∏ô 0.80
            if similarity > 0.80:
                for existing in self.processed_items:
                    if existing.get('title') == cached_orig_title:
                        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏î‡πâ‡∏ß‡∏¢ - ‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏Å‡πá‡πÑ‡∏°‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏ã‡πâ‡∏≥
                        if existing.get('country') != item.get('country'):
                            continue
                        return True, f"Title ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å + ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô ({similarity:.1%})"
        
        # ‚úÖ FIX 2: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå keyword matching ‡∏à‡∏≤‡∏Å 0.70 -> 0.85
        current_keywords = self.extract_keywords(f"{item.get('title', '')} {item.get('summary', '')}")
        if len(current_keywords) >= 3:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3 keywords
            for existing in self.processed_items:
                existing_keywords = self.extract_keywords(
                    f"{existing.get('title', '')} {existing.get('summary', '')}"
                )
                
                # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å 0.7 ‡πÄ‡∏õ‡πá‡∏ô 0.85 (‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô 85%+)
                common_keywords = current_keywords & existing_keywords
                if len(common_keywords) >= len(current_keywords) * 0.85:
                    title_sim = self.calculate_similarity(item.get('title', ''), existing.get('title', ''))
                    # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å 0.5 ‡πÄ‡∏õ‡πá‡∏ô 0.70
                    if title_sim > 0.70:
                        pub_dt1 = item.get('published_dt')
                        pub_dt2 = existing.get('published_dt')
                        if pub_dt1 and pub_dt2:
                            time_diff = abs((pub_dt1 - pub_dt2).total_seconds() / 3600)
                            # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å 48 ‡∏ä‡∏°. ‡πÄ‡∏õ‡πá‡∏ô 24 ‡∏ä‡∏°.
                            if time_diff < 24:
                                return True, f"‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô {len(common_keywords)} ‡∏Ñ‡∏≥ + title ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô + ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ô"
        
        # ‚úÖ FIX 3: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö specific terms
        specific_terms = self._extract_specific_terms(title)
        if len(specific_terms) >= 2:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á
            for existing in self.processed_items:
                existing_terms = self._extract_specific_terms(existing.get('title', ''))
                common_terms = specific_terms & existing_terms
                if len(common_terms) >= 2:  # ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏Ñ‡∏≥
                    title_sim = self.calculate_similarity(title, existing.get('title', ''))
                    if title_sim > 0.75:  # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å 0.5 -> 0.75
                        return True, f"‡∏û‡∏ö‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏ã‡πâ‡∏≥: {', '.join(common_terms)}"
        
        norm_title = self.normalize_text(title)
        self.title_cache.append((norm_title, title))
        
        return False, None
    
    def is_duplicate_url(self, url: str) -> bool:
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö URL ‡∏ã‡πâ‡∏≥"""
        normalized = normalize_url(url)
        if normalized in self.seen_urls:
            return True
        self.seen_urls.add(normalized)
        return False
    
    def _extract_specific_terms(self, text: str) -> Set[str]:
        """‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á ‡πÄ‡∏ä‡πà‡∏ô ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£, ‡∏™‡∏ñ‡∏≤‡∏ô‡∏ó‡∏µ‡πà, ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà"""
        text_lower = text.lower()
        specific_terms = set()
        
        # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ
        date_patterns = [
            r'\d{1,2}\s*‡∏°\.‡∏Ñ\.',
            r'\d{1,2}\s*‡∏Å\.‡∏û\.',
            r'\d{1,2}\s*‡∏°‡∏µ\.‡∏Ñ\.',
            r'\d{1,2}/\d{1,2}/\d{2,4}',
            r'‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ',
            r'today'
        ]
        
        for pattern in date_patterns:
            matches = re.findall(pattern, text_lower)
            specific_terms.update(matches)
        
        # ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏â‡∏û‡∏≤‡∏∞
        project_names = [
            'natuna sea a', 'natuna', 'arthit', 'zawtika', 'yadana',
            'sk309', 'sk311', 'block h', 'block 61', 'dunga',
            '‡∏à‡∏µ 1/61', '‡∏à‡∏µ 2/61', '‡πÄ‡∏≠‡∏™ 1', '‡∏ö‡∏µ 6/27',
            'indonesia', 'malaysia', 'vietnam', 'myanmar', 'oman', 'uae',
            'leighton asia', 'cimic', 'aiib', 'pasuruan'
        ]
        
        for project in project_names:
            if project in text_lower:
                specific_terms.add(project)
        
        # ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (‡∏£‡∏≤‡∏Ñ‡∏≤, ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏á‡∏¥‡∏ô)
        number_patterns = re.findall(r'\$\d+|\d+\s*(?:‡∏ö‡∏≤‡∏ó|‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå|‡∏•‡πâ‡∏≤‡∏ô|‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô)', text_lower)
        specific_terms.update(number_patterns[:2])  # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 2 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å
        
        return specific_terms
        
    def add_item(self, item: dict) -> bool:
        """‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏ö (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥)"""
        is_dup, reason = self.is_duplicate_content(item)
        
        if is_dup:
            if DEBUG_FILTERING:
                print(f"  ‚úó ‡∏Ç‡πà‡∏≤‡∏ß‡∏ã‡πâ‡∏≥: {reason}")
            return False
        
        self.processed_items.append(item)
        return True


# =============================================================================
# KEYWORD FILTER (FIXED - Less Strict)
# =============================================================================
class KeywordFilter:
    """‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç - ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏ô‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô"""
    
    ENERGY_KEYWORDS = [
        '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô', '‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', '‡∏Ñ‡πà‡∏≤‡πÑ‡∏ü', '‡∏Ñ‡πà‡∏≤‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', '‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Ñ‡πà‡∏≤‡πÑ‡∏ü‡∏ü‡πâ‡∏≤',
        '‡∏Å‡πä‡∏≤‡∏ã', 'LNG', '‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô', '‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÄ‡∏û‡∏•‡∏¥‡∏á', '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏î‡πÅ‡∏ó‡∏ô',
        '‡πÇ‡∏£‡∏á‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', '‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡πÅ‡∏™‡∏á‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå', '‡πÇ‡∏ã‡∏•‡∏≤‡∏£‡πå', '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏•‡∏°',
        '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ä‡∏µ‡∏ß‡∏°‡∏ß‡∏•', '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ô‡πâ‡∏≥', '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡πâ‡∏≠‡∏ô',
        '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ô‡∏¥‡∏ß‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå', '‡∏ñ‡πà‡∏≤‡∏ô‡∏´‡∏¥‡∏ô', '‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ü‡∏≠‡∏™‡∏ã‡∏¥‡∏•',
        '‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô', '‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô', '‡πÅ‡∏ú‡∏ô‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô', '‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô',
        '‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô', '‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô', '‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô‡∏Å‡πä‡∏≤‡∏ã', '‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô',
        '‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Å‡πä‡∏≤‡∏ã', '‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô', '‡πÅ‡∏´‡∏•‡πà‡∏á‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô',
        '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Å‡πä‡∏≤‡∏ã', '‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏ü‡∏ü‡πâ‡∏≤',
        '‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô', '‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô',
        'energy', 'electricity', 'power', 'gas', 'oil', 'fuel',
        'power plant', 'renewable', 'solar', 'wind', 'biomass',
        'energy policy', 'energy project', 'energy investment',
        # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        'crude', 'petroleum', 'brent', 'wti', 'opec',
        '‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏î‡∏¥‡∏ö', '‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°', '‡πÇ‡∏≠‡πÄ‡∏õ‡∏Å'
    ]
    
    ENERGY_MARKET_KEYWORDS = [
        '‡∏£‡∏≤‡∏Ñ‡∏≤', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô', '‡∏£‡∏≤‡∏Ñ‡∏≤‡∏Å‡πä‡∏≤‡∏ã', '‡∏£‡∏≤‡∏Ñ‡∏≤‡πÑ‡∏ü‡∏ü‡πâ‡∏≤', '‡∏Ñ‡πà‡∏≤‡πÑ‡∏ü',
        '‡∏ï‡∏•‡∏≤‡∏î', '‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô', '‡∏ï‡∏•‡∏≤‡∏î‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô', '‡∏ï‡∏•‡∏≤‡∏î‡∏Å‡πä‡∏≤‡∏ã',
        '‡πÇ‡∏•‡∏Å', '‡πÇ‡∏•‡∏Å‡∏≤', '‡∏ï‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®', '‡∏™‡∏´‡∏£‡∏±‡∏ê', '‡πÄ‡∏ß‡πÄ‡∏ô‡∏ã‡∏∏‡πÄ‡∏≠‡∏•‡∏≤',
        '‡∏£‡πà‡∏ß‡∏á', '‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô', '‡∏õ‡∏£‡∏±‡∏ö‡∏•‡∏î', '‡∏ú‡∏±‡∏ô‡∏ú‡∏ß‡∏ô', '‡∏ï‡∏Å', '‡πÄ‡∏û‡∏¥‡πà‡∏°',
        '‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå', '‡∏ö‡∏≤‡∏£‡πå‡πÄ‡∏£‡∏•', '‡∏ï‡∏•‡∏≤‡∏î‡∏´‡∏∏‡πâ‡∏ô', '‡∏ï‡∏•‡∏≤‡∏î‡πÇ‡∏•‡∏Å',
        'price', 'market', 'global', 'crude', 'brent', 'wti',
        'increase', 'decrease', 'drop', 'rise', 'fall',
        # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        'trading', 'futures', 'commodity', 'barrel',
        '‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢', '‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤', '‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÇ‡∏†‡∏Ñ‡∏†‡∏±‡∏ì‡∏ë‡πå'
    ]
    
    BUSINESS_KEYWORDS = [
        '‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£', '‡∏•‡∏á‡∏ó‡∏∏‡∏ô', '‡∏™‡∏±‡∏ç‡∏ç‡∏≤', '‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô', '‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤',
        '‡∏•‡πâ‡∏≤‡∏ô', '‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô', '‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå', '‡∏ö‡∏≤‡∏ó', '‡πÄ‡∏´‡∏£‡∏µ‡∏¢‡∏ç',
        '‡∏û‡∏ö', '‡∏™‡∏≥‡∏£‡∏ß‡∏à', '‡∏Ç‡∏∏‡∏î‡πÄ‡∏à‡∏≤‡∏∞', '‡∏ú‡∏•‡∏¥‡∏ï', '‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å', '‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤',
        '‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®', '‡πÅ‡∏ñ‡∏•‡∏á', '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô', '‡∏ú‡∏•‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£', '‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ',
        '‡∏Ç‡∏¢‡∏≤‡∏¢', '‡∏û‡∏±‡∏í‡∏ô‡∏≤', '‡∏™‡∏£‡πâ‡∏≤‡∏á', '‡∏Å‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á', '‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á',
        '‡∏ï‡∏•‡∏≤‡∏î', '‡∏ã‡∏∑‡πâ‡∏≠', '‡∏Ç‡∏≤‡∏¢', '‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢', '‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≤‡∏¢‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤',
        '‡∏´‡∏∏‡πâ‡∏ô', '‡∏ï‡∏•‡∏≤‡∏î‡∏´‡∏∏‡πâ‡∏ô', '‡∏ï‡∏•‡∏≤‡∏î‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå', '‡∏ï‡∏•‡∏≤‡∏î‡πÇ‡∏•‡∏Å',
        '‡πÄ‡∏û‡∏¥‡πà‡∏°', '‡∏•‡∏î', '‡∏õ‡∏£‡∏±‡∏ö', '‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á', '‡∏ß‡∏¥‡∏Å‡∏§‡∏ï', '‡πÇ‡∏≠‡∏Å‡∏≤‡∏™',
        'project', 'investment', 'contract', 'agreement', 'deal',
        'discovery', 'exploration', 'drilling', 'production', 'export',
        'announce', 'report', 'financial', 'revenue', 'expand',
        'development', 'construction', 'installation',
        'market', 'trading', 'stock', 'exchange', 'global',
        # ‚úÖ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á
        'growth', 'decline', 'forecast', 'outlook', 'trend',
        '‡πÄ‡∏ï‡∏¥‡∏ö‡πÇ‡∏ï', '‡∏•‡∏î‡∏•‡∏á', '‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå', '‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏°', '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå'
    ]
    
    EXCLUDE_KEYWORDS = [
        '‡∏ï‡∏•‡∏≤‡∏î‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå', '‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå', '‡∏£‡∏ñ', '‡∏£‡∏ñ‡πÉ‡∏´‡∏°‡πà', '‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå‡πÉ‡∏´‡∏°‡πà',
        '‡∏¢‡∏≤‡∏ô‡∏¢‡∏ô‡∏ï‡πå', '‡∏≠‡∏∏‡∏ï‡∏™‡∏≤‡∏´‡∏Å‡∏£‡∏£‡∏°‡∏¢‡∏≤‡∏ô‡∏¢‡∏ô‡∏ï‡πå',
        '‡∏î‡∏≤‡∏£‡∏≤', '‡∏®‡∏¥‡∏•‡∏õ‡∏¥‡∏ô', '‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á', '‡∏ô‡∏±‡∏Å‡∏£‡πâ‡∏≠‡∏á', '‡∏Ñ‡∏ô‡∏î‡∏±‡∏á',
        '‡∏£‡πà‡∏ß‡∏°‡∏ö‡∏∏‡∏ç', '‡∏Å‡∏≤‡∏£‡∏Å‡∏∏‡∏®‡∏•', '‡∏à‡∏¥‡∏ï‡∏≠‡∏≤‡∏™‡∏≤', '‡∏°‡∏≠‡∏ö', '‡πÉ‡∏´‡πâ', '‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠',
        'celebrity', 'actor', 'singer', 'donation', 'charity', 'philanthropy',
        'car', 'automotive', 'vehicle', 'automobile'
    ]
    
    @classmethod
    def check_valid_energy_news(cls, text: str) -> tuple:
        """
        ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        
        FIXED: ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ï‡∏•‡∏≤‡∏î = ‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à)
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏Ñ‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à = ‡∏ú‡πà‡∏≤‡∏ô
        - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® = ‡∏ú‡πà‡∏≤‡∏ô
        """
        text_lower = text.lower()
        reasons = []
        
        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏≥‡∏ï‡πâ‡∏≠‡∏á‡∏´‡πâ‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô
        for exclude in cls.EXCLUDE_KEYWORDS:
            if exclude.lower() in text_lower:
                reasons.append(f"‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡πâ‡∏≠‡∏á‡∏´‡πâ‡∏≤‡∏°: '{exclude}'")
                return False, "‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏±‡∏á‡∏Ñ‡∏°", reasons
        
        found_energy_keywords = [kw for kw in cls.ENERGY_KEYWORDS if kw.lower() in text_lower]
        found_market_keywords = [kw for kw in cls.ENERGY_MARKET_KEYWORDS if kw.lower() in text_lower]
        found_business_keywords = [kw for kw in cls.BUSINESS_KEYWORDS if kw.lower() in text_lower]
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡πÄ‡∏•‡∏¢
        if not found_energy_keywords and not found_market_keywords:
            reasons.append("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô")
            return False, "‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô", reasons
        
        if found_energy_keywords:
            reasons.append(f"‡∏û‡∏ö‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô: {', '.join(found_energy_keywords[:3])}")
        if found_market_keywords:
            reasons.append(f"‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô: {', '.join(found_market_keywords[:3])}")
        if found_business_keywords:
            reasons.append(f"‡∏û‡∏ö‡∏Ñ‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à: {', '.join(found_business_keywords[:3])}")
        
        # ‚úÖ FIX: ‡∏ú‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç
        
        # 1. ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ï‡∏•‡∏≤‡∏î = ‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        if found_energy_keywords and found_market_keywords:
            reasons.append("‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏£‡∏≤‡∏Ñ‡∏≤/‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô")
            return True, "‡∏ú‡πà‡∏≤‡∏ô", reasons
        
        # 2. ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏Ñ‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à = ‡∏ú‡πà‡∏≤‡∏ô
        if found_energy_keywords and found_business_keywords:
            reasons.append("‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏Ñ‡∏≥‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à")
            return True, "‡∏ú‡πà‡∏≤‡∏ô", reasons
        
        # 3. ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® = ‡∏ú‡πà‡∏≤‡∏ô
        country_keywords = ['thailand', 'vietnam', 'malaysia', 'indonesia', 'myanmar', 
                           'oman', 'uae', 'kazakhstan', '‡πÑ‡∏ó‡∏¢', '‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏°', '‡∏°‡∏≤‡πÄ‡∏•‡πÄ‡∏ã‡∏µ‡∏¢', 
                           '‡∏≠‡∏¥‡∏ô‡πÇ‡∏î‡∏ô‡∏µ‡πÄ‡∏ã‡∏µ‡∏¢', '‡πÄ‡∏°‡∏µ‡∏¢‡∏ô‡∏°‡∏≤', '‡πÇ‡∏≠‡∏°‡∏≤‡∏ô', '‡∏¢‡∏π‡πÄ‡∏≠‡∏≠‡∏µ', '‡∏Ñ‡∏≤‡∏ã‡∏±‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô']
        if found_energy_keywords and any(country in text_lower for country in country_keywords):
            reasons.append("‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®")
            return True, "‡∏ú‡πà‡∏≤‡∏ô", reasons
        
        # 4. ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡πÉ‡∏´‡∏ç‡πà, ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç, ‡∏´‡∏•‡∏±‡∏Å, ‡∏Ø‡∏•‡∏Ø) = ‡∏ú‡πà‡∏≤‡∏ô
        if found_energy_keywords and any(word in text_lower for word in 
                                         ['‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç', '‡πÉ‡∏´‡∏ç‡πà', '‡∏´‡∏•‡∏±‡∏Å', '‡πÇ‡∏•‡∏Å', 'global', 
                                          'major', 'significant', 'important', 'key']):
            reasons.append("‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç")
            return True, "‡∏ú‡πà‡∏≤‡∏ô", reasons
        
        # 5. ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô ‡πÅ‡∏ï‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏°‡∏≤‡∏Å‡∏û‡∏≠ = ‡∏ú‡πà‡∏≤‡∏ô
        if found_energy_keywords and len(text) > 100:  # ‡∏Ç‡πà‡∏≤‡∏ß‡∏¢‡∏≤‡∏ß‡∏Å‡∏ß‡πà‡∏≤ 100 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
            reasons.append("‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + ‡∏Ç‡πà‡∏≤‡∏ß‡∏¢‡∏≤‡∏ß‡∏û‡∏≠‡∏™‡∏°‡∏Ñ‡∏ß‡∏£")
            return True, "‡∏ú‡πà‡∏≤‡∏ô", reasons
        
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÉ‡∏î‡πÄ‡∏•‡∏¢
        reasons.append("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à/‡∏ï‡∏•‡∏≤‡∏î/‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®")
        return False, "‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏Ç‡πà‡∏≤‡∏ß‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à", reasons
    
    @classmethod
    def detect_country(cls, text: str) -> str:
        """Detect country from text"""
        text_lower = text.lower()
        
        country_patterns = {
            "Thailand": ['‡πÑ‡∏ó‡∏¢', '‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢', 'thailand', 'bangkok'],
            "Myanmar": ['‡πÄ‡∏°‡∏µ‡∏¢‡∏ô‡∏°‡∏≤', 'myanmar', '‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏∏‡πâ‡∏á', 'yangon'],
            "Malaysia": ['‡∏°‡∏≤‡πÄ‡∏•‡πÄ‡∏ã‡∏µ‡∏¢', 'malaysia', '‡∏Å‡∏±‡∏ß‡∏•‡∏≤‡∏•‡∏±‡∏°‡πÄ‡∏õ‡∏≠‡∏£‡πå', 'kuala lumpur'],
            "Vietnam": ['‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏°', 'vietnam', '‡∏Æ‡∏≤‡∏ô‡∏≠‡∏¢', 'hanoi'],
            "Indonesia": ['‡∏≠‡∏¥‡∏ô‡πÇ‡∏î‡∏ô‡∏µ‡πÄ‡∏ã‡∏µ‡∏¢', 'indonesia', '‡∏à‡∏≤‡∏Å‡∏≤‡∏£‡πå‡∏ï‡∏≤', 'jakarta'],
            "Kazakhstan": ['‡∏Ñ‡∏≤‡∏ã‡∏±‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô', 'kazakhstan', 'astana'],
            "Oman": ['‡πÇ‡∏≠‡∏°‡∏≤‡∏ô', 'oman', 'muscat'],
            "UAE": ['‡∏¢‡∏π‡πÄ‡∏≠‡∏≠‡∏µ', 'uae', '‡∏î‡∏π‡πÑ‡∏ö', 'dubai', '‡∏≠‡∏≤‡∏ö‡∏π‡∏î‡∏≤‡∏ö‡∏µ', 'abu dhabi']
        }
        
        for country, patterns in country_patterns.items():
            if any(pattern in text_lower for pattern in patterns):
                return country
        
        return ""

# =============================================================================
# FEEDS
# =============================================================================
def gnews_rss(q: str, hl="en", gl="US", ceid="US:en") -> str:
    return f"https://news.google.com/rss/search?q={requests.utils.quote(q)}&hl={hl}&gl={gl}&ceid={ceid}"

FEEDS = [
    ("GoogleNewsTH", "thai", gnews_rss(
        '(‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô OR "‡∏Ñ‡πà‡∏≤‡πÑ‡∏ü" OR ‡∏Å‡πä‡∏≤‡∏ã OR LNG OR ‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô OR ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤ OR "‡πÇ‡∏£‡∏á‡πÑ‡∏ü‡∏ü‡πâ‡∏≤" OR "‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏ó‡∏î‡πÅ‡∏ó‡∏ô" OR "‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô") -"‡∏£‡∏ñ‡∏¢‡∏ô‡∏ï‡πå" -"‡∏ï‡∏•‡∏≤‡∏î‡∏£‡∏ñ" -"‡∏î‡∏≤‡∏£‡∏≤" -"‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á"',
        hl="th", gl="TH", ceid="TH:th"
    )),
    ("GoogleNewsEN", "international", gnews_rss(
        '(energy OR electricity OR power OR oil OR gas OR "power plant" OR "energy project") AND (Thailand OR Vietnam OR Malaysia OR Indonesia) -car -automotive -celebrity',
        hl="en", gl="US", ceid="US:en"
    )),
]

# =============================================================================
# UTILITIES
# =============================================================================
def now_tz() -> datetime:
    return datetime.now(TZ)

def normalize_url(url: str) -> str:
    url = (url or "").strip()
    if not url:
        return url
    try:
        u = urlparse(url)
        return u._replace(fragment="").geturl()
    except Exception:
        return url

def extract_domain(url: str) -> str:
    """Extract domain name from URL"""
    url = normalize_url(url)
    if not url:
        return ""
    try:
        domain = urlparse(url).netloc.lower()
        if domain.startswith("www."):
            domain = domain[4:]
        return domain
    except Exception:
        return ""

def is_allowed_source(url: str) -> bool:
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ URL ‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
    if not ALLOWED_NEWS_SOURCES_LIST:
        return True
    
    domain = extract_domain(url)
    if not domain:
        return False
    
    for allowed_source in ALLOWED_NEWS_SOURCES_LIST:
        if allowed_source in domain:
            return True
    
    return False

def shorten_google_news_url(url: str) -> str:
    """Extract actual URL from Google News redirect"""
    url = normalize_url(url)
    if not url:
        return url
    try:
        u = urlparse(url)
        if "news.google.com" in u.netloc:
            qs = parse_qs(u.query)
            if "url" in qs and qs["url"]:
                return normalize_url(unquote(qs["url"][0]))
    except Exception:
        pass
    return url

def read_sent_links() -> set:
    sent = set()
    for fn in os.listdir(SENT_DIR):
        if not fn.endswith(".txt"):
            continue
        fp = os.path.join(SENT_DIR, fn)
        try:
            with open(fp, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line:
                        sent.add(line)
        except Exception:
            continue
    return sent

def append_sent_link(url: str):
    url = normalize_url(url)
    if not url:
        return
    fn = os.path.join(SENT_DIR, now_tz().strftime("%Y-%m-%d") + ".txt")
    with open(fn, "a", encoding="utf-8") as f:
        f.write(url + "\n")

def in_time_window(published_dt: datetime, hours: int) -> bool:
    if not published_dt:
        return False
    return published_dt >= (now_tz() - timedelta(hours=hours))

def cut(s: str, n: int) -> str:
    s = (s or "").strip()
    return s if len(s) <= n else s[: n - 1].rstrip() + "‚Ä¶"

def create_simple_summary(text: str, max_length: int = 150) -> str:
    """Create a simple summary from text"""
    text = (text or "").strip()
    if not text:
        return ""
    
    text = ' '.join(text.split())
    sentences = re.split(r'[.!?]', text)
    if sentences and len(sentences[0]) > 10:
        summary = sentences[0].strip()
        if len(summary) > max_length:
            summary = summary[:max_length-1] + "‚Ä¶"
        return summary + "."
    
    if len(text) > max_length:
        return text[:max_length-1] + "‚Ä¶"
    return text

# =============================================================================
# RSS PARSING
# =============================================================================
def fetch_feed_with_retry(name: str, url: str, retries: int = 3):
    """‡∏î‡∏∂‡∏á feed ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö retry"""
    for attempt in range(retries):
        try:
            print(f"[FEED] ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {name} (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà {attempt+1}/{retries})...")
            d = feedparser.parse(url)
            entries = d.entries or []
            print(f"[FEED] {name}: ‡∏û‡∏ö {len(entries)} entries")
            return entries
        except Exception as e:
            print(f"[FEED] {name}: ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î - {str(e)}")
            if attempt < retries - 1:
                time.sleep(2 ** attempt)
            else:
                return []

def parse_entry(e, feed_name: str, section: str):
    title = (getattr(e, "title", "") or "").strip()
    link = (getattr(e, "link", "") or "").strip()
    summary = (getattr(e, "summary", "") or "").strip()
    published = getattr(e, "published", None) or getattr(e, "updated", None)

    if not published and hasattr(e, 'published_parsed'):
        try:
            import time as time_module
            published = time_module.strftime('%Y-%m-%dT%H:%M:%SZ', e.published_parsed)
        except:
            pass

    try:
        published_dt = dateutil_parser.parse(published) if published else None
        if published_dt and published_dt.tzinfo is None:
            published_dt = TZ.localize(published_dt)
        if published_dt:
            published_dt = published_dt.astimezone(TZ)
    except Exception:
        published_dt = None

    canon = shorten_google_news_url(link)

    return {
        "title": title,
        "url": normalize_url(link),
        "canon_url": normalize_url(canon),
        "summary": summary,
        "published_dt": published_dt,
        "feed": feed_name,
        "section": section,
    }

# =============================================================================
# LLM ANALYZER
# =============================================================================
# =============================================================================
# LLM ANALYZER (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏î‡πâ‡∏ß‡∏¢ Few-Shot Learning)
# =============================================================================
class LLMAnalyzer:
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢ LLM ‡∏û‡∏£‡πâ‡∏≠‡∏° Few-Shot Learning"""
    
    def __init__(self, api_key: str, model: str, endpoint: str):
        self.api_key = api_key
        self.model = model
        self.endpoint = endpoint
        # ‚ú® ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Few-Shot Learning
        self.example_news = get_few_shot_examples()
        print(f"[LLM] ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Few-Shot Learning ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
    
    def analyze_news(self, title: str, summary: str) -> dict:
        """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡πâ‡∏ß‡∏¢ LLM + Few-Shot Learning"""
        if not self.api_key:
            return self._get_default_analysis(title, summary)
        
        # ‚ú® System Prompt ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
        system_prompt = f"""‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ:

{self.example_news}

‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô:
- ‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö: ‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à, ‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏¥‡∏ï, ‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô, ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ï‡∏•‡∏≤‡∏î, ‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢, ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô
- ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏†‡∏π‡∏°‡∏¥‡∏£‡∏±‡∏ê‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏ï‡∏•‡∏≤‡∏î‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô (‡∏≠‡∏¥‡∏´‡∏£‡πà‡∏≤‡∏ô, ‡∏£‡∏±‡∏™‡πÄ‡∏ã‡∏µ‡∏¢, ‡πÄ‡∏ß‡πÄ‡∏ô‡∏ã‡∏∏‡πÄ‡∏≠‡∏•‡∏≤, OPEC)
- ‡πÑ‡∏°‡πà‡∏£‡∏±‡∏ö: ‡∏Ç‡πà‡∏≤‡∏ß‡∏¢‡∏≤‡∏ô‡∏¢‡∏ô‡∏ï‡πå, ‡∏Ç‡πà‡∏≤‡∏ß‡∏ö‡∏±‡∏ô‡πÄ‡∏ó‡∏¥‡∏á, ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏±‡∏á‡∏Ñ‡∏°, ‡∏Ç‡πà‡∏≤‡∏ß‡∏Å‡∏≤‡∏£‡∏Å‡∏∏‡∏®‡∏•

‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô:
{{
    "relevant": true/false,
    "country": "‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (Thailand/Vietnam/Malaysia/etc) ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á",
    "summary_th": "‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏±‡πâ‡∏ô‡πÜ 1 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ",
    "topics": ["‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠1", "‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠2"],
    "confidence": 0.0-1.0
}}"""
        
        user_prompt = f"""‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ:

‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {title}
‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤: {summary[:500]}

‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:
1. ‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà?
2. ‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏´‡∏ô?
3. ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ 1 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ"""
        
        try:
            response = requests.post(
                self.endpoint,
                headers={
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    "temperature": 0.1,
                    "max_tokens": 400
                },
                timeout=30
            )
            
            if response.status_code != 200:
                print(f"[LLM] HTTP Error {response.status_code}")
                return self._get_default_analysis(title, summary)
            
            data = response.json()
            content = data["choices"][0]["message"]["content"].strip()
            
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                analysis = json.loads(json_match.group())
                
                confidence = float(analysis.get("confidence", 0.5))
                relevant = bool(analysis.get("relevant", True))
                
                if confidence < 0.7 and DEBUG_FILTERING:
                    print(f"[LLM] ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ï‡πà‡∏≥ ({confidence:.2f}): {title[:40]}...")
                
                return {
                    "relevant": relevant,
                    "country": str(analysis.get("country", "")).strip(),
                    "summary_th": str(analysis.get("summary_th", "")).strip()[:150],
                    "topics": [str(t).strip() for t in analysis.get("topics", []) if t],
                    "confidence": confidence
                }
                
        except json.JSONDecodeError:
            print("[LLM] Failed to parse JSON response")
        except Exception as e:
            print(f"[LLM] Error: {str(e)}")
        
        return self._get_default_analysis(title, summary)
    
    def _get_default_analysis(self, title: str, summary: str):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô"""
        combined = f"{title} {summary}"
        simple_summary = create_simple_summary(combined, 100)
        
        return {
            "relevant": True,
            "country": "",
            "summary_th": simple_summary if simple_summary else "‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô",
            "topics": [],
            "confidence": 0.5
        }
# =============================================================================
# NEWS PROCESSOR
# =============================================================================
class NewsProcessor:
    def __init__(self):
        self.sent_links = read_sent_links()
        self.llm_analyzer = LLMAnalyzer(GROQ_API_KEY, GROQ_MODEL, GROQ_ENDPOINT) if GROQ_API_KEY else None
        self.dedup = EnhancedDeduplication()
        
        self.news_sources = {
            'reuters.com': 'Reuters',
            'bloomberg.com': 'Bloomberg',
            'bangkokpost.com': 'Bangkok Post',
            'thansettakij.com': '‡∏ê‡∏≤‡∏ô‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à',
            'posttoday.com': 'Post Today',
            'prachachat.net': '‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏≤‡∏ï‡∏¥‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à',
            'mgronline.com': '‡∏ú‡∏π‡πâ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏≠‡∏≠‡∏ô‡πÑ‡∏•‡∏ô‡πå',
            'komchadluek.net': '‡∏Ñ‡∏°‡∏ä‡∏±‡∏î‡∏•‡∏∂‡∏Å',
            'nationthailand.com': 'The Nation Thailand',
            'naewna.com': '‡πÅ‡∏ô‡∏ß‡∏´‡∏ô‡πâ‡∏≤',
            'dailynews.co.th': '‡πÄ‡∏î‡∏•‡∏¥‡∏ô‡∏¥‡∏ß‡∏™‡πå',
            'thairath.co.th': '‡πÑ‡∏ó‡∏¢‡∏£‡∏±‡∏ê',
            'khaosod.co.th': '‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏î',
            'matichon.co.th': '‡∏°‡∏ï‡∏¥‡∏ä‡∏ô',
        }
        
        self.filter_stats = {
            'total_processed': 0,
            'filtered_by': {
                'no_title': 0,
                'no_url': 0,
                'already_sent': 0,
                'out_of_window': 0,
                'not_allowed_source': 0,
                'invalid_energy_news': 0,
                'no_country': 0,
                'duplicate': 0,
                'passed': 0
            }
        }
        
        self.filtered_news = []
    
    def get_source_name(self, url: str) -> str:
        """‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ß‡πá‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å URL"""
        domain = extract_domain(url)
        if not domain:
            return domain
        
        for source_domain, source_name in self.news_sources.items():
            if source_domain in domain:
                return source_name
        
        return domain
    
    def fetch_and_filter_news(self):
        """Fetch and filter news from all feeds"""
        all_news = []
        
        for feed_name, feed_type, feed_url in FEEDS:
            print(f"\n[Fetching] {feed_name} ({feed_type})...")
            
            try:
                entries = fetch_feed_with_retry(feed_name, feed_url)
                
                for entry in entries[:MAX_PER_FEED]:
                    self.filter_stats['total_processed'] += 1
                    news_item, filter_reason = self._process_entry(entry, feed_name, feed_type)
                    if news_item:
                        all_news.append(news_item)
                        self.filter_stats['filtered_by']['passed'] += 1
                        print(f"  ‚úì {news_item['title'][:50]}...")
                    elif filter_reason and DEBUG_FILTERING:
                        print(f"  ‚úó {filter_reason}")
                        
            except Exception as e:
                print(f"  ‚úó Error: {str(e)}")
        
        all_news.sort(key=lambda x: -((x.get('published_dt') or datetime.min).timestamp()))
        
        return all_news
    
     def _process_entry(self, entry, feed_name: str, feed_type: str):
        """Process individual news entry"""
        item = parse_entry(entry, feed_name, feed_type)
        
        if not item["title"]:
            self.filter_stats['filtered_by']['no_title'] += 1
            return None, "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏Ç‡πà‡∏≤‡∏ß"
        
        if not item["url"]:
            self.filter_stats['filtered_by']['no_url'] += 1
            return None, "‡πÑ‡∏°‡πà‡∏°‡∏µ URL"
        
        if item["canon_url"] in self.sent_links or item["url"] in self.sent_links:
            self.filter_stats['filtered_by']['already_sent'] += 1
            return None, f"‡∏™‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß: {item['title'][:30]}..."
        
        if item["published_dt"] and not in_time_windo
project_hints = PROJECTS_BY_COUNTRY.get(country, [])[:2]
    display_url = item["canon_url"] or item["url"]
    source_name = self.get_source_name(display_url)
    
    final_item = {
        'title': item['title'][:100],
        'url': item['url'],
        'canon_url': item['canon_url'],
        'source_name': source_name,
        'domain': extract_domain(display_url),
        'summary': item['summary'][:200],
        'published_dt': item['published_dt'],
        'country': country,
        'project_hints': project_hints,
        'llm_summary': llm_summary,
        'feed': feed_name,
        'feed_type': feed_type,
        'simple_summary': create_simple_summary(full_text, 100)
    }
    
    if not self.dedup.add_item(final_item):
        self.filter_stats['filtered_by']['duplicate'] += 1
        return None, f"‡∏Ç‡πà‡∏≤‡∏ß‡∏ã‡πâ‡∏≥: {item['title'][:30]}..."
    
    return final_item, None
# =============================================================================
# LINE MESSAGE BUILDER
# =============================================================================
class LineMessageBuilder:
    @staticmethod
    def create_flex_bubble(news_item):
        """Create a LINE Flex Bubble for a news item"""
        title = cut(news_item.get('title', ''), 80)
        
        pub_dt = news_item.get('published_dt')
        time_str = pub_dt.strftime("%d/%m/%Y %H:%M") if pub_dt else ""
        
        colors = {
            "Thailand": "#FF6B6B",
            "Vietnam": "#4ECDC4",
            "Myanmar": "#FFD166",
            "Malaysia": "#06D6A0",
            "Indonesia": "#118AB2",
            "UAE": "#9D4EDD",
            "Oman": "#F15BB5",
            "Kazakhstan": "#00BBF9",
            "International": "#888888"
        }
        
        color = colors.get(news_item.get('country', 'International'), "#888888")
        
        contents = [
            {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {
                        "type": "text",
                        "text": title,
                        "weight": "bold",
                        "size": "md",
                        "wrap": True,
                        "color": "#FFFFFF"
                    }
                ],
                "backgroundColor": color,
                "paddingAll": "12px",
                "cornerRadius": "8px"
            }
        ]
        
        metadata_parts = []
        if time_str:
            metadata_parts.append(time_str)
        if news_item.get('feed'):
            metadata_parts.append(news_item['feed'])
        
        if metadata_parts:
            contents.append({
                "type": "text",
                "text": " | ".join(metadata_parts),
                "size": "xs",
                "color": "#888888",
                "margin": "sm"
            })
        
        if news_item.get('source_name'):
            contents.append({
                "type": "text",
                "text": f"üì∞ {news_item['source_name']}",
                "size": "xs",
                "color": "#666666",
                "margin": "sm"
            })
        
        contents.append({
            "type": "text",
            "text": f"‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®: {news_item.get('country', 'N/A')}",
            "size": "sm",
            "margin": "xs",
            "color": color,
            "weight": "bold"
        })
        
        if news_item.get('project_hints'):
            hints_text = ", ".join(news_item['project_hints'][:2])
            contents.append({
                "type": "text",
                "text": f"‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á: {hints_text}",
                "size": "sm",
                "color": "#2E7D32",
                "wrap": True,
                "margin": "xs"
            })
        
        summary_text = ""
        if news_item.get('llm_summary'):
            summary_text = news_item['llm_summary']
        elif news_item.get('simple_summary'):
            summary_text = news_item['simple_summary']
        elif news_item.get('summary'):
            summary_text = create_simple_summary(news_item['summary'], 120)
        
        if not summary_text or len(summary_text.strip()) < 10:
            summary_text = f"{news_item.get('title', '‡∏Ç‡πà‡∏≤‡∏ß‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô')[:60]}..."
        
        if summary_text:
            contents.append({
                "type": "text",
                "text": cut(summary_text, 120),
                "size": "sm",
                "wrap": True,
                "margin": "md",
                "color": "#424242"
            })
        
        bubble = {
            "type": "bubble",
            "size": "kilo",
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": contents,
                "paddingAll": "12px",
                "spacing": "sm"
            }
        }
        
        url = news_item.get('canon_url') or news_item.get('url')
        if url and len(url) < 1000:
            bubble["footer"] = {
                "type": "box",
                "layout": "vertical",
                "spacing": "sm",
                "contents": [
                    {
                        "type": "button",
                        "style": "primary",
                        "height": "sm",
                        "action": {
                            "type": "uri",
                            "label": "‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏ï‡πá‡∏°",
                            "uri": url
                        }
                    }
                ]
            }
        
        return bubble
    
    @staticmethod
    def create_carousel_message(news_items):
        """Create LINE carousel message from news items"""
        bubbles = []
        
        for item in news_items[:BUBBLES_PER_CAROUSEL]:
            bubble = LineMessageBuilder.create_flex_bubble(item)
            if bubble:
                bubbles.append(bubble)
        
        if not bubbles:
            return None
        
        return {
            "type": "flex",
            "altText": f"‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πà‡∏≤‡∏ß‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô {datetime.now(TZ).strftime('%d/%m/%Y')} ({len(bubbles)} ‡∏Ç‡πà‡∏≤‡∏ß)",
            "contents": {
                "type": "carousel",
                "contents": bubbles
            }
        }

# =============================================================================
# LINE SENDER
# =============================================================================
class LineSender:
    def __init__(self, access_token):
        self.access_token = access_token
        self.headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-Type": "application/json"
        }
    
    def send_message(self, message_obj):
        """Send message to LINE"""
        if DRY_RUN:
            print("\n" + "="*60)
            print("DRY RUN - Would send message")
            print("="*60)
            print(json.dumps(message_obj, indent=2, ensure_ascii=False)[:500])
            return True
        
        url = "https://api.line.me/v2/bot/message/broadcast"
        
        try:
            response = requests.post(
                url,
                headers=self.headers,
                json={"messages": [message_obj]},
                timeout=30
            )
            
            if response.status_code == 200:
                print("[LINE] Message sent successfully!")
                return True
            else:
                print(f"[LINE] Error {response.status_code}: {response.text[:200]}")
                return False
                
        except Exception as e:
            print(f"[LINE] Exception: {str(e)}")
            return False

# =============================================================================
# WTI FUTURES MODULE - Real Market Data (NYMEX via Public APIs)
# =============================================================================
# =============================================================================
# WTI FUTURES MODULE - Yahoo Finance Primary Source (FIXED)
# =============================================================================
class WTIFuturesFetcher:
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤ WTI Futures ‡∏à‡∏≤‡∏Å Yahoo Finance (Primary) + EIA (Fallback)"""
    
    def __init__(self, api_key: str = None):
        """Initialize WTI Futures Fetcher"""
        self.eia_api_key = api_key
        self.eia_base_url = "https://api.eia.gov/v2"
    
    def fetch_futures_from_yahoo(self) -> Tuple[List[Dict], float]:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• WTI Futures ‡∏à‡∏≤‡∏Å Yahoo Finance (Primary Method)"""
        try:
            print("[WTI/Yahoo] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Futures ‡∏à‡∏≤‡∏Å Yahoo Finance...")
            
            # Yahoo Finance WTI Futures symbols (NYMEX)
            contracts = {
                'CL=F': 'Front Month',
                'CLG26.NYM': 'Feb 2026',
                'CLH26.NYM': 'Mar 2026',
                'CLJ26.NYM': 'Apr 2026',
                'CLK26.NYM': 'May 2026',
                'CLM26.NYM': 'Jun 2026',
                'CLN26.NYM': 'Jul 2026',
                'CLQ26.NYM': 'Aug 2026',
                'CLU26.NYM': 'Sep 2026',
                'CLV26.NYM': 'Oct 2026',
                'CLX26.NYM': 'Nov 2026',
                'CLZ26.NYM': 'Dec 2026',
                'CLF27.NYM': 'Jan 2027'
            }
            
            futures_data = []
            base_price = None
            
            for symbol, month_label in contracts.items():
                try:
                    url = f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}"
                    params = {
                        'interval': '1d',
                        'range': '5d'
                    }
                    
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                    }
                    
                    response = requests.get(url, params=params, headers=headers, timeout=10)
                    
                    if response.status_code == 200:
                        data = response.json()
                        
                        if 'chart' in data and 'result' in data['chart'] and data['chart']['result']:
                            result = data['chart']['result'][0]
                            
                            if 'meta' in result and 'regularMarketPrice' in result['meta']:
                                price = result['meta']['regularMarketPrice']
                                
                                if symbol == 'CL=F':
                                    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏Ñ‡∏≤ Front Month ‡πÄ‡∏õ‡πá‡∏ô base
                                    base_price = price
                                    print(f"[WTI/Yahoo] ‚úì Current Price: ${price:.2f}/barrel")
                                else:
                                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì change ‡∏à‡∏≤‡∏Å Front Month (base_price) ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà previous close
                                    if base_price:
                                        change = price - base_price
                                        change_pct = (change / base_price) * 100
                                    else:
                                        # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ base ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ previous close
                                        prev_close = result['meta'].get('chartPreviousClose', price)
                                        change = price - prev_close
                                        change_pct = (change / prev_close) * 100 if prev_close else 0
                                    
                                    futures_data.append({
                                        "month": month_label,
                                        "contract": symbol.replace('.NYM', ''),
                                        "price": round(price, 2),
                                        "change": round(change, 2),
                                        "change_pct": round(change_pct, 2)
                                    })
                    
                    time.sleep(0.2)  # Rate limiting
                    
                except Exception as e:
                    print(f"[WTI/Yahoo] Warning for {symbol}: {str(e)}")
                    continue
            
            if futures_data and base_price:
                print(f"[WTI/Yahoo] ‚úì ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(futures_data)} ‡∏™‡∏±‡∏ç‡∏ç‡∏≤")
                return futures_data, base_price
            
            return [], None
                
        except Exception as e:
            print(f"[WTI/Yahoo] Error: {str(e)}")
            return [], None
    
    def fetch_current_wti_price(self) -> Tuple[float, str]:
        """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ WTI Spot Price ‡∏à‡∏≤‡∏Å EIA (Fallback only)"""
        if not self.eia_api_key:
            return None, None
            
        url = f"{self.eia_base_url}/petroleum/pri/spt/data/"
        params = {
            "api_key": self.eia_api_key,
            "frequency": "daily",
            "data[0]": "value",
            "facets[product][]": "EPCWTI",
            "sort[0][column]": "period",
            "sort[0][direction]": "desc",
            "length": 1
        }
        
        try:
            print(f"[WTI/EIA] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ WTI Spot Price (Fallback)...")
            response = requests.get(url, params=params, timeout=15)
            response.raise_for_status()
            data = response.json()
            
            response_data = data['response']['data']
            if response_data:
                price = float(response_data[0]['value'])
                period = response_data[0].get('period', '')
                print(f"[WTI/EIA] ‚úì Spot Price: ${price:.2f}/barrel ({period})")
                return price, period
                
        except Exception as e:
            print(f"[WTI/EIA] Warning: {str(e)}")
        
        return None, None
    
    def _estimate_futures_from_spot(self, spot_price: float) -> List[Dict]:
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì futures ‡∏à‡∏≤‡∏Å spot price (Emergency fallback)"""
        futures_data = []
        now = datetime.now(TZ)
        
        # Contango curve based on historical patterns
        # WTI typically shows ~$0.25-0.50 per month contango
        monthly_premium = 0.35
        
        for i in range(12):
            months_ahead = i + 1
            future_date = now + timedelta(days=30 * months_ahead)
            
            # Simple contango calculation
            premium = months_ahead * monthly_premium
            future_price = spot_price + premium
            
            futures_data.append({
                "month": future_date.strftime("%b %Y"),
                "contract": future_date.strftime("%b%y").upper(),
                "price": round(future_price, 2),
                "change": round(premium, 2),
                "change_pct": round((premium / spot_price) * 100, 2)
            })
        
        return futures_data
    
    def get_current_and_futures(self) -> Dict:
        """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡πÅ‡∏•‡∏∞ futures (Yahoo Finance First)"""
        print("\n[WTI] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏Ñ‡∏≤ WTI Futures...")
        
        # Strategy 1: Try Yahoo Finance first (Best quality, real-time data)
        futures_data, current_price = self.fetch_futures_from_yahoo()
        
        if futures_data and current_price:
            print(f"[WTI] ‚úì ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Yahoo Finance - {len(futures_data)} ‡∏™‡∏±‡∏ç‡∏ç‡∏≤")
            
            return {
                "current": {
                    "source": "Yahoo Finance (NYMEX)",
                    "current_price": current_price,
                    "timestamp": datetime.now(TZ).isoformat(),
                    "currency": "USD/barrel",
                    "commodity": "WTI Crude Oil Futures"
                },
                "futures": futures_data[:12],
                "updated_at": datetime.now(TZ).strftime("%d/%m/%Y %H:%M"),
                "is_estimated": False,
                "method": "Real-time data from Yahoo Finance (NYMEX)"
            }
        
        # Strategy 2: Fallback to EIA Spot + Estimation
        print("[WTI] Yahoo Finance ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ EIA Spot Price...")
        spot_price, spot_date = self.fetch_current_wti_price()
        
        if spot_price:
            print(f"[WTI] ‚úì ‡πÉ‡∏ä‡πâ EIA Spot Price + ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Futures")
            futures_data = self._estimate_futures_from_spot(spot_price)
            
            return {
                "current": {
                    "source": f"U.S. EIA Spot Price ({spot_date})",
                    "current_price": spot_price,
                    "timestamp": datetime.now(TZ).isoformat(),
                    "currency": "USD/barrel",
                    "commodity": "WTI Crude Oil (Cushing, OK)"
                },
                "futures": futures_data,
                "updated_at": datetime.now(TZ).strftime("%d/%m/%Y %H:%M"),
                "is_estimated": True,
                "method": "EIA spot price + statistical estimation"
            }
        
        # Strategy 3: Use default fallback
        print("[WTI] ‚ö†Ô∏è ‡∏ó‡∏∏‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô")
        default_price = 75.00
        
        return {
            "current": {
                "source": "Default Estimate",
                "current_price": default_price,
                "timestamp": datetime.now(TZ).isoformat(),
                "currency": "USD/barrel",
                "commodity": "WTI Crude Oil"
            },
            "futures": self._estimate_futures_from_spot(default_price),
            "updated_at": datetime.now(TZ).strftime("%d/%m/%Y %H:%M"),
            "is_estimated": True,
            "method": "Emergency fallback (all sources failed)"
        }


class WTIFlexMessageBuilder:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á LINE Flex Message ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ WTI Futures"""
    
    @staticmethod
    def create_wti_futures_message(data: dict) -> dict:
        """‡∏™‡∏£‡πâ‡∏≤‡∏á Flex Message ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤ WTI Futures ‡∏Ñ‡∏£‡∏ö 12 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô"""
        current = data.get("current", {})
        futures = data.get("futures", [])
        updated_at = data.get("updated_at", "")
        current_price = current.get("current_price", 0)
        is_estimated = data.get("is_estimated", True)
        method = data.get("method", "")
        source = current.get("source", "Unknown")
        
        header_contents = {
            "type": "box",
            "layout": "vertical",
            "contents": [
                {
                    "type": "text",
                    "text": "üõ¢Ô∏è WTI Crude Oil Futures",
                    "weight": "bold",
                    "size": "xl",
                    "color": "#FFFFFF"
                },
                {
                    "type": "text",
                    "text": "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ô‡πâ‡∏≥‡∏°‡∏±‡∏ô‡∏•‡πà‡∏ß‡∏á‡∏´‡∏ô‡πâ‡∏≤ 12 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô",
                    "size": "sm",
                    "color": "#FFFFFF",
                    "margin": "xs"
                }
            ],
            "backgroundColor": "#1E3A8A",
            "paddingAll": "20px"
        }
        
        current_box = {
            "type": "box",
            "layout": "vertical",
            "contents": [
                {
                    "type": "text",
                    "text": "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (Front Month)",
                    "size": "sm",
                    "color": "#8B8B8B",
                    "weight": "bold"
                },
                {
                    "type": "text",
                    "text": f"${current_price:.2f}",
                    "size": "xxl",
                    "weight": "bold",
                    "color": "#1E3A8A",
                    "margin": "xs"
                },
                {
                    "type": "text",
                    "text": "per barrel",
                    "size": "xs",
                    "color": "#8B8B8B",
                    "margin": "xs"
                }
            ],
            "backgroundColor": "#F0F9FF",
            "cornerRadius": "10px",
            "paddingAll": "15px",
            "margin": "md"
        }
        
        table_header = {
            "type": "box",
            "layout": "horizontal",
            "contents": [
                {
                    "type": "text",
                    "text": "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô",
                    "size": "xs",
                    "color": "#FFFFFF",
                    "weight": "bold",
                    "flex": 2
                },
                {
                    "type": "text",
                    "text": "‡∏£‡∏≤‡∏Ñ‡∏≤",
                    "size": "xs",
                    "color": "#FFFFFF",
                    "weight": "bold",
                    "align": "end",
                    "flex": 2
                },
                {
                    "type": "text",
                    "text": "‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô",
                    "size": "xs",
                    "color": "#FFFFFF",
                    "weight": "bold",
                    "align": "end",
                    "flex": 1
                }
            ],
            "backgroundColor": "#3B82F6",
            "paddingAll": "10px",
            "cornerRadius": "5px",
            "margin": "lg"
        }
        
        futures_rows = []
        for i, future in enumerate(futures[:12]):
            month = future.get("month", "")
            price = future.get("price", 0)
            change_pct = future.get("change_pct", 0)
            
            change_color = "#16A34A" if change_pct >= 0 else "#DC2626"
            change_symbol = "+" if change_pct >= 0 else ""
            
            row = {
                "type": "box",
                "layout": "horizontal",
                "contents": [
                    {
                        "type": "text",
                        "text": month,
                        "size": "sm",
                        "color": "#333333",
                        "flex": 2
                    },
                    {
                        "type": "text",
                        "text": f"${price:.2f}",
                        "size": "sm",
                        "color": "#333333",
                        "align": "end",
                        "weight": "bold",
                        "flex": 2
                    },
                    {
                        "type": "text",
                        "text": f"{change_symbol}{change_pct:.1f}%",
                        "size": "xs",
                        "color": change_color,
                        "align": "end",
                        "weight": "bold",
                        "flex": 1
                    }
                ],
                "paddingAll": "8px",
                "backgroundColor": "#F9FAFB" if i % 2 == 0 else "#FFFFFF"
            }
            futures_rows.append(row)
        
        footer_contents = [
            {
                "type": "separator",
                "margin": "md"
            },
            {
                "type": "text",
                "text": f"‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï: {updated_at}",
                "size": "xs",
                "color": "#8B8B8B",
                "align": "center",
                "margin": "md"
            },
            {
                "type": "text",
                "text": f"üì° ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {source}",
                "size": "xxs",
                "color": "#8B8B8B",
                "align": "center",
                "margin": "xs"
            }
        ]
        
        if is_estimated:
            footer_contents.append({
                "type": "text",
                "text": "‚ö†Ô∏è ‡∏£‡∏≤‡∏Ñ‡∏≤ Futures ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Å‡∏≤‡∏£",
                "size": "xxs",
                "color": "#F59E0B",
                "align": "center",
                "margin": "xs"
            })
        else:
            footer_contents.append({
                "type": "text",
                "text": "‚úÖ ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏•‡∏≤‡∏î NYMEX",
                "size": "xxs",
                "color": "#16A34A",
                "align": "center",
                "margin": "xs"
            })
        
        footer = {
            "type": "box",
            "layout": "vertical",
            "contents": footer_contents
        }
        
        bubble = {
            "type": "bubble",
            "size": "mega",
            "header": header_contents,
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    current_box,
                    table_header,
                    *futures_rows,
                    footer
                ],
                "paddingAll": "0px"
            }
        }
        
        return {
            "type": "flex",
            "altText": f"‡∏£‡∏≤‡∏Ñ‡∏≤ WTI Crude Oil Futures: ${current_price:.2f}/barrel",
            "contents": bubble
        }

# =============================================================================
# MAIN FUNCTION
# =============================================================================
def main():
    print("="*60)
    print("‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô + WTI Futures (EIA API)")
    print("="*60)
    
    if not LINE_CHANNEL_ACCESS_TOKEN:
        print("[ERROR] LINE_CHANNEL_ACCESS_TOKEN is required")
        return
    
    if not EIA_API_KEY:
        print("[ERROR] EIA_API_KEY is required")
        print("        Get one from: https://www.eia.gov/opendata/")
        return
    
    if USE_LLM_SUMMARY and not GROQ_API_KEY:
        print("[WARNING] LLM summary enabled but no GROQ_API_KEY provided")
        print("[INFO] Will use simple summary for all news")
    
    print(f"\n[CONFIG] Use LLM: {'Yes' if USE_LLM_SUMMARY and GROQ_API_KEY else 'No'}")
    print(f"[CONFIG] Time window: {WINDOW_HOURS} hours")
    print(f"[CONFIG] Dry run: {'Yes' if DRY_RUN else 'No'}")
    print(f"[CONFIG] Debug filtering: {'Yes' if DEBUG_FILTERING else 'No'}")
    print(f"[CONFIG] WTI Data Source: EIA (U.S. Energy Information Administration)")
    
    processor = NewsProcessor()
    line_sender = LineSender(LINE_CHANNEL_ACCESS_TOKEN)
    
    print("\n[1] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πà‡∏≤‡∏ß...")
    news_items = processor.fetch_and_filter_news()
    
    print(f"\n[FILTER STATISTICS]")
    print(f"  ‡∏£‡∏ß‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {processor.filter_stats['total_processed']}")
    print(f"  ‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á: {processor.filter_stats['filtered_by']['passed']}")
    print(f"  ‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á: {processor.filter_stats['total_processed'] - processor.filter_stats['filtered_by']['passed']}")
    
    if processor.filter_stats['total_processed'] - processor.filter_stats['filtered_by']['passed'] > 0:
        print(f"\n  ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á:")
        for reason, count in processor.filter_stats['filtered_by'].items():
            if reason != 'passed' and count > 0:
                print(f"    - {reason}: {count} ‡∏Ç‡πà‡∏≤‡∏ß")
    
    success_news = False
    if not news_items:
        print("\n[INFO] ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á")
    else:
        print(f"\n[2] ‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(news_items)} ‡∏Ç‡πà‡∏≤‡∏ß")
        
        llm_summary_count = sum(1 for item in news_items if item.get('llm_summary'))
        source_counts = {}
        country_counts = {}
        
        for item in news_items:
            source = item.get('source_name') or item.get('domain', 'Unknown')
            source_counts[source] = source_counts.get(source, 0) + 1
            
            country = item.get('country', 'Unknown')
            country_counts[country] = country_counts.get(country, 0) + 1
        
        print(f"   - ‡∏™‡∏£‡∏∏‡∏õ‡∏î‡πâ‡∏ß‡∏¢ AI: {llm_summary_count} ‡∏Ç‡πà‡∏≤‡∏ß")
        print(f"   - ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏û‡∏ö:")
        for source, count in sorted(source_counts.items()):
            print(f"     ‚Ä¢ {source}: {count} ‡∏Ç‡πà‡∏≤‡∏ß")
        print(f"   - ‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®:")
        for country, count in sorted(country_counts.items()):
            print(f"     ‚Ä¢ {country}: {count} ‡∏Ç‡πà‡∏≤‡∏ß")
        
        print("\n[3] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° LINE...")
        line_message = LineMessageBuilder.create_carousel_message(news_items)
        
        if line_message:
            print("\n[4] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô...")
            success_news = line_sender.send_message(line_message)
        else:
            print("[WARNING] ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏î‡πâ")
    
    print("\n[5] ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• WTI Futures...")
    success_wti = False
    try:
        wti_fetcher = WTIFuturesFetcher(api_key=EIA_API_KEY)
        wti_data = wti_fetcher.get_current_and_futures()
        wti_message = WTIFlexMessageBuilder.create_wti_futures_message(wti_data)
        
        success_wti = line_sender.send_message(wti_message)
        
    except Exception as e:
        print(f"[WTI ERROR] {str(e)}")
    
    if news_items and not DRY_RUN:
        for item in news_items:
            append_sent_link(item.get('canon_url') or item.get('url'))
        print("\n[SUCCESS] ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß")
    
    print("\n" + "="*60)
    if news_items:
        print(f"‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô - ‡∏™‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß: {'‚úì' if success_news else '‚úó'}, ‡∏™‡πà‡∏á WTI: {'‚úì' if success_wti else '‚úó'}")
    else:
        print(f"‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô - ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà, ‡∏™‡πà‡∏á WTI: {'‚úì' if success_wti else '‚úó'}")
    print("="*60)

if __name__ == "__main__":
    main()
