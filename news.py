# ============================================================================================================
# PTTEP Domestic-by-Project-Countries News Bot (WITH Legacy Sources)
# - ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ topic keyword filter (energy/econ/politics) ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏´‡∏•‡∏±‡∏Å
# - ‡∏™‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà "‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®" ‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
# - ‡∏£‡∏ß‡∏°‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß: Google News RSS (‡πÅ‡∏¢‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®) + ‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏î‡∏¥‡∏° (global feeds)
# ============================================================================================================

import os
import re
import json
import time
import random
from datetime import datetime, timedelta
from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode, quote_plus

import feedparser
from dateutil import parser as dateutil_parser
import pytz
import requests
import google.generativeai as genai

try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "").strip()

if not GEMINI_API_KEY:
    raise RuntimeError("‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY")
if not LINE_CHANNEL_ACCESS_TOKEN:
    raise RuntimeError("‡πÑ‡∏°‡πà‡∏û‡∏ö LINE_CHANNEL_ACCESS_TOKEN")

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel(os.getenv("GEMINI_MODEL_NAME", "gemini-2.5-flash"))

GEMINI_DAILY_BUDGET = int(os.getenv("GEMINI_DAILY_BUDGET", "250"))
MAX_RETRIES = 6
SLEEP_BETWEEN_CALLS = (0.5, 1.0)

DRY_RUN = os.getenv("DRY_RUN", "false").lower() == "true"

# ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ LLM ‡∏ï‡πà‡∏≠‡∏£‡∏±‡∏ô (‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á)
MAX_LLM_ITEMS = int(os.getenv("MAX_LLM_ITEMS", "24"))
# ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Google News ‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®)
MAX_PER_COUNTRY = int(os.getenv("MAX_PER_COUNTRY", "4"))
# ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏î‡∏¥‡∏° (global feeds) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏Å‡∏¥‡∏ô‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤
MAX_GLOBAL_ITEMS = int(os.getenv("MAX_GLOBAL_ITEMS", "6"))

bangkok_tz = pytz.timezone("Asia/Bangkok")
S = requests.Session()
S.headers.update({"User-Agent": "Mozilla/5.0"})
TIMEOUT = 15

SENT_LINKS_DIR = "sent_links"
os.makedirs(SENT_LINKS_DIR, exist_ok=True)

DEFAULT_ICON_URL = "https://scdn.line-apps.com/n/channel_devcenter/img/fx/01_1_cafe.png"

# ------------------------------------------------------------------------------------------------------------
# Countries with PTTEP projects
# ------------------------------------------------------------------------------------------------------------
PROJECT_COUNTRIES = [
    "Thailand", "Myanmar", "Vietnam", "Malaysia", "Indonesia",
    "UAE", "Oman", "Algeria", "Mozambique", "Australia", "Brazil", "Mexico"
]

PROJECT_COUNTRY_SYNONYMS = {
    "Thailand": ["thailand", "thai", "bangkok", "‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢", "‡πÑ‡∏ó‡∏¢"],
    "Myanmar": ["myanmar", "burma", "‡πÄ‡∏°‡∏µ‡∏¢‡∏ô‡∏°‡∏≤", "‡∏û‡∏°‡πà‡∏≤"],
    "Vietnam": ["vietnam", "viet nam", "‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏°"],
    "Malaysia": ["malaysia", "malaysian", "‡∏°‡∏≤‡πÄ‡∏•‡πÄ‡∏ã‡∏µ‡∏¢"],
    "Indonesia": ["indonesia", "indonesian", "‡∏≠‡∏¥‡∏ô‡πÇ‡∏î‡∏ô‡∏µ‡πÄ‡∏ã‡∏µ‡∏¢"],
    "UAE": ["uae", "united arab emirates", "abu dhabi", "dubai", "‡∏™‡∏´‡∏£‡∏±‡∏ê‡∏≠‡∏≤‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏°‡∏¥‡πÄ‡∏£‡∏ï‡∏™‡πå"],
    "Oman": ["oman", "‡πÇ‡∏≠‡∏°‡∏≤‡∏ô"],
    "Algeria": ["algeria", "algerian", "‡πÅ‡∏≠‡∏•‡∏à‡∏µ‡πÄ‡∏£‡∏µ‡∏¢"],
    "Mozambique": ["mozambique", "rovuma", "‡πÇ‡∏°‡∏ã‡∏±‡∏°‡∏ö‡∏¥‡∏Å"],
    "Australia": ["australia", "australian", "‡∏≠‡∏≠‡∏™‡πÄ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢"],
    "Brazil": ["brazil", "brazilian", "‡∏ö‡∏£‡∏≤‡∏ã‡∏¥‡∏•"],
    "Mexico": ["mexico", "mexican", "‡πÄ‡∏°‡πá‡∏Å‡∏ã‡∏¥‡πÇ‡∏Å"],
}

def detect_project_countries(text: str):
    t = (text or "").lower()
    hits = []
    for c, keys in PROJECT_COUNTRY_SYNONYMS.items():
        if any(k in t for k in keys):
            hits.append(c)
    return sorted(set(hits))

# ------------------------------------------------------------------------------------------------------------
# Google News RSS per country (domestic-ish)
# ------------------------------------------------------------------------------------------------------------
COUNTRY_QUERY = {
    "Thailand": "Thailand OR ‡πÑ‡∏ó‡∏¢ OR ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ OR Bangkok",
    "Myanmar": "Myanmar OR Burma OR ‡πÄ‡∏°‡∏µ‡∏¢‡∏ô‡∏°‡∏≤ OR ‡∏û‡∏°‡πà‡∏≤",
    "Vietnam": "Vietnam OR ‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏°",
    "Malaysia": "Malaysia OR ‡∏°‡∏≤‡πÄ‡∏•‡πÄ‡∏ã‡∏µ‡∏¢",
    "Indonesia": "Indonesia OR ‡∏≠‡∏¥‡∏ô‡πÇ‡∏î‡∏ô‡∏µ‡πÄ‡∏ã‡∏µ‡∏¢",
    "UAE": "UAE OR \"United Arab Emirates\" OR Abu Dhabi OR Dubai OR ‡∏™‡∏´‡∏£‡∏±‡∏ê‡∏≠‡∏≤‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏≠‡∏°‡∏¥‡πÄ‡∏£‡∏ï‡∏™‡πå",
    "Oman": "Oman OR ‡πÇ‡∏≠‡∏°‡∏≤‡∏ô",
    "Algeria": "Algeria OR ‡πÅ‡∏≠‡∏•‡∏à‡∏µ‡πÄ‡∏£‡∏µ‡∏¢",
    "Mozambique": "Mozambique OR ‡πÇ‡∏°‡∏ã‡∏±‡∏°‡∏ö‡∏¥‡∏Å OR Rovuma",
    "Australia": "Australia OR ‡∏≠‡∏≠‡∏™‡πÄ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢",
    "Brazil": "Brazil OR ‡∏ö‡∏£‡∏≤‡∏ã‡∏¥‡∏•",
    "Mexico": "Mexico OR ‡πÄ‡∏°‡πá‡∏Å‡∏ã‡∏¥‡πÇ‡∏Å",
}

def google_news_rss(q: str, hl="en", gl="US", ceid="US:en"):
    return f"https://news.google.com/rss/search?q={quote_plus(q)}&hl={hl}&gl={gl}&ceid={ceid}"

# ------------------------------------------------------------------------------------------------------------
# Legacy sources (global feeds)
# NOTE: ‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏≤‡∏Å‡∏û‡∏ß‡∏Å‡∏ô‡∏µ‡πâ‡∏à‡∏∞ "‡∏ú‡πà‡∏≤‡∏ô" ‡πÑ‡∏î‡πâ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ñ‡πâ‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ + ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏£‡∏¥‡∏á ‡πÜ
# ------------------------------------------------------------------------------------------------------------
LEGACY_FEEDS = [
    ("Oilprice", "GLOBAL", "https://oilprice.com/rss/main"),
    ("CleanTechnica", "GLOBAL", "https://cleantechnica.com/feed/"),
    ("HydrogenFuelNews", "GLOBAL", "https://www.hydrogenfuelnews.com/feed/"),
    ("Economist", "GLOBAL", "https://www.economist.com/latest/rss.xml"),
    ("YahooFinance", "GLOBAL", "https://finance.yahoo.com/news/rssindex"),
]

# ‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô NEWS_FEEDS
NEWS_FEEDS = []
for c in PROJECT_COUNTRIES:
    NEWS_FEEDS.append(("GoogleNews", c, google_news_rss(COUNTRY_QUERY[c])))
NEWS_FEEDS.extend(LEGACY_FEEDS)

# ============================================================================================================
# HELPERS
# ============================================================================================================
def _normalize_link(url: str) -> str:
    try:
        p = urlparse(url)
        netloc = p.netloc.lower()
        scheme = (p.scheme or "https").lower()

        drop = {"fbclid", "gclid", "ref", "mc_cid", "mc_eid"}
        new_q = [
            (k, v)
            for k, v in parse_qsl(p.query, keep_blank_values=True)
            if not (k.startswith("utm_") or k in drop)
        ]
        return urlunparse(p._replace(scheme=scheme, netloc=netloc, query=urlencode(new_q)))
    except Exception:
        return (url or "").strip()

def get_sent_links_file(date=None):
    if date is None:
        date = datetime.now(bangkok_tz).strftime("%Y-%m-%d")
    return os.path.join(SENT_LINKS_DIR, f"{date}.txt")

def load_sent_links():
    sent = set()
    today_str = datetime.now(bangkok_tz).strftime("%Y-%m-%d")
    p = get_sent_links_file(today_str)
    if os.path.exists(p):
        with open(p, "r", encoding="utf-8") as f:
            for line in f:
                u = _normalize_link(line.strip())
                if u:
                    sent.add(u)
    return sent

def save_sent_links(links):
    p = get_sent_links_file()
    with open(p, "a", encoding="utf-8") as f:
        for l in links:
            f.write(_normalize_link(l) + "\n")

def _impact_to_bullets(text: str):
    if not text:
        return ["‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£"]
    lines = [l.strip() for l in text.splitlines() if l.strip()]
    if not lines:
        lines = [text.strip()]
    bullets = []
    for line in lines:
        s = line.strip()
        s = re.sub(r"^[\u2022\*\-\u00b7¬∑‚Ä¢\s]+", "", s)
        s = re.sub(r"^\d+[\.\)]\s*", "", s)
        if s.startswith(".*"):
            s = s[2:].lstrip()
        if s.startswith("*"):
            s = s[1:].lstrip()
        if s:
            bullets.append(s)
    return bullets or ["‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£"]

def has_meaningful_impact(impact_text: str) -> bool:
    if not impact_text:
        return False
    t = impact_text.lower().replace(" ", "")
    bad = ["‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö", "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö", "‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠"]
    if any(x.replace(" ", "") in t for x in bad):
        return False
    return len(impact_text.strip()) >= 20

def _extract_json_object(raw: str):
    if not raw:
        return None
    s = raw.strip()
    if s.startswith("```"):
        s = re.sub(r"^```(json)?", "", s, flags=re.I).strip()
        s = re.sub(r"```$", "", s).strip()
    try:
        return json.loads(s)
    except Exception:
        pass
    first = s.find("{")
    last = s.rfind("}")
    if first != -1 and last != -1 and last > first:
        candidate = s[first:last + 1]
        try:
            return json.loads(candidate)
        except Exception:
            return None
    return None

# ============================================================================================================
# Fetch hero image
# ============================================================================================================
def fetch_article_image(url: str) -> str:
    if not url:
        return ""
    try:
        r = S.get(url, timeout=TIMEOUT, allow_redirects=True)
        if r.status_code >= 400:
            return ""
        html = r.text
        m = re.search(r'<meta[^>]+property=[\'"]og:image[\'"][^>]+content=[\'"]([^\'"]+)[\'"]', html, re.I)
        if m:
            return m.group(1)
        m = re.search(r'<meta[^>]+name=[\'"]twitter:image[\'"][^>]+content=[\'"]([^\'"]+)[\'"]', html, re.I)
        if m:
            return m.group(1)
        m = re.search(r'<img[^>]+src=[\'"]([^\'"]+)[\'"]', html, re.I)
        if m:
            src = m.group(1)
            if src.startswith("//"):
                parsed = urlparse(url)
                return f"{parsed.scheme}:{src}"
            if src.startswith("/"):
                parsed = urlparse(url)
                return f"{parsed.scheme}://{parsed.netloc}{src}"
            return src
        return ""
    except Exception:
        return ""

# ============================================================================================================
# CONTEXT
# ============================================================================================================
PTTEP_PROJECTS_CONTEXT = r"""
[PTTEP_PROJECTS_CONTEXT]

‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ (Thailand)
- G1/61 (Erawan, Platong, Satun, Funan)
- G2/61 (Bongkot ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á)
- Arthit, S1, Contract 4, B8/32, 9A, Sinphuhorm, MTJDA Block A-18

‡πÄ‡∏°‡∏µ‡∏¢‡∏ô‡∏°‡∏≤ (Myanmar) ‚Äì Zawtika, Yadana, Yetagun
‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏° (Vietnam) ‚Äì Block B & 48/95, Block 52/97, 16-1 (Te Giac Trang)
‡∏°‡∏≤‡πÄ‡∏•‡πÄ‡∏ã‡∏µ‡∏¢ (Malaysia) ‚Äì MTJDA Block A-18, SK309, SK311, SK410B ‡∏Ø‡∏•‡∏Ø
‡∏≠‡∏¥‡∏ô‡πÇ‡∏î‡∏ô‡∏µ‡πÄ‡∏ã‡∏µ‡∏¢ (Indonesia) ‚Äì South Sageri, South Mandar, Malunda ‡∏Ø‡∏•‡∏Ø
UAE ‚Äì Ghasha Concession, Abu Dhabi Offshore
Oman ‚Äì Oman Block 12
Algeria ‚Äì Bir Seba, Hirad, Touat ‡∏Ø‡∏•‡∏Ø
Mozambique ‚Äì Mozambique Area 1 (Rovuma LNG)
Australia ‚Äì Montara ‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡πÉ‡∏ô Timor Sea / Browse Basin
Brazil ‚Äì BM-ES-23, BM-ES-24 ‡∏Ø‡∏•‡∏Ø
Mexico ‚Äì Mexico Block 12 (2.4) ‡πÅ‡∏•‡∏∞‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô ‡πÜ
"""

PARTNERS_CONTEXT = r"""
[‡∏û‡∏±‡∏ô‡∏ò‡∏°‡∏¥‡∏ï‡∏£ / ‡∏ú‡∏π‡πâ‡∏£‡πà‡∏ß‡∏°‡∏ó‡∏∏‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢]
- Chevron, ExxonMobil, TotalEnergies, Shell, BP, ENI, Sonatrach, Petrobras,
  ADNOC, Petronas ‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡πÅ‡∏´‡πà‡∏á‡∏ä‡∏≤‡∏ï‡∏¥‡∏≠‡∏∑‡πà‡∏ô ‡πÜ
"""

# ============================================================================================================
# GEMINI CALL WRAPPER
# ============================================================================================================
GEMINI_CALLS = 0

def call_gemini(prompt: str, want_json: bool = False):
    global GEMINI_CALLS
    if GEMINI_CALLS >= GEMINI_DAILY_BUDGET:
        raise RuntimeError("‡πÄ‡∏Å‡∏¥‡∏ô‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤ Gemini ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô")

    last_error = None
    for i in range(1, MAX_RETRIES + 1):
        try:
            gen_cfg = {"temperature": 0.2, "max_output_tokens": 900}
            if want_json:
                gen_cfg["response_mime_type"] = "application/json"
            try:
                r = model.generate_content(prompt, generation_config=gen_cfg)
            except TypeError:
                r = model.generate_content(prompt)
            GEMINI_CALLS += 1
            return r
        except Exception as e:
            last_error = e
            if any(x in str(e) for x in ["429", "unavailable", "deadline", "503", "500"]) and i < MAX_RETRIES:
                time.sleep(5 * i)
                continue
            raise e
    raise last_error

def rule_fallback(news):
    feed_country = (news.get("feed_country") or "").strip()
    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö legacy/global: ‡∏à‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ feed_country ‡∏à‡∏£‡∏¥‡∏á ‡πÜ -> ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏°‡∏µ countries_hint ‡∏ä‡∏±‡∏î ‡πÜ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1
    if feed_country == "GLOBAL":
        hints = news.get("countries_hint") or []
        if len(hints) != 1:
            return {"is_relevant": False}
        return {
            "is_relevant": True,
            "summary": "",
            "topic_type": "other",
            "region": "other",
            "impact_reason": "‚Ä¢ ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡∏ó‡∏≤‡∏á‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢/‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à/‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô/‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏á‡∏≤‡∏ô/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ô‡∏±‡πâ‡∏ô",
            "country": hints[0],
            "projects": ["ALL"],
        }

    # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö GoogleNews per-country: feed_country ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ô‡∏±‡πâ‡∏ô
    if feed_country not in PROJECT_COUNTRIES:
        return {"is_relevant": False}
    return {
        "is_relevant": True,
        "summary": "",
        "topic_type": "other",
        "region": "other",
        "impact_reason": "‚Ä¢ ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô/‡∏Å‡∏é‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö/‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏á‡∏≤‡∏ô/‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ô‡∏µ‡πâ",
        "country": feed_country,
        "projects": ["ALL"],
    }

# ============================================================================================================
# GEMINI TAG + FILTER
# ============================================================================================================
def gemini_tag_and_filter(news):
    schema = {
        "type": "object",
        "properties": {
            "is_relevant": {"type": "boolean"},
            "summary": {"type": "string"},
            "topic_type": {
                "type": "string",
                "enum": ["supply_disruption", "price_move", "policy", "investment", "geopolitics", "other"],
            },
            "region": {
                "type": "string",
                "enum": ["global", "asia", "europe", "middle_east", "us", "other"],
            },
            "impact_reason": {"type": "string"},
            "country": {"type": "string"},
            "projects": {"type": "array", "items": {"type": "string"}},
        },
        "required": ["is_relevant"],
    }

    feed_country = (news.get("feed_country") or "").strip()
    countries_hint = news.get("countries_hint") or []

    # ‡πÇ‡∏´‡∏°‡∏î‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß:
    # - GoogleNews per-country: feed_country ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®
    # - Legacy feeds: feed_country = "GLOBAL" (‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ LLM ‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏à‡∏≤‡∏Å allowed list)
    mode = "per_country" if (feed_country in PROJECT_COUNTRIES) else "global"

    prompt = f"""
{PTTEP_PROJECTS_CONTEXT}
{PARTNERS_CONTEXT}

‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: Analyst + News Screener ‡∏Ç‡∏≠‡∏á PTTEP
‡πÇ‡∏à‡∏ó‡∏¢‡πå: ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ "‡∏Ç‡πà‡∏≤‡∏ß‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®" ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¥‡∏á keyword ‡∏´‡∏°‡∏ß‡∏î‡∏Ç‡πà‡∏≤‡∏ß)

‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï (‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£): {PROJECT_COUNTRIES}

‡πÇ‡∏´‡∏°‡∏î‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πà‡∏≤‡∏ß: {mode}
- ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏°‡∏î per_country: ‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏à‡∏≤‡∏Å feed ‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® = {feed_country}
- ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏°‡∏î global: ‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö global (‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏≠‡∏á ‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï)

Hints ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡πà‡∏≤‡∏ß (‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ):
countries_hint = {countries_hint}

‡∏Å‡∏ï‡∏¥‡∏Å‡∏≤‡πÅ‡∏ö‡∏ö‡πÄ‡∏Ç‡πâ‡∏° (STRICT):
1) ‡∏´‡πâ‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ô‡∏≠‡∏Å‡∏•‡∏¥‡∏™‡∏ï‡πå:
   - ‡∏ñ‡πâ‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ‚Üí is_relevant = false
2) ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô "‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ô‡∏±‡πâ‡∏ô" ‡∏à‡∏£‡∏¥‡∏á ‡πÜ:
   - ‡∏ñ‡πâ‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô global/‡∏Ç‡πâ‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®/‡∏ï‡∏•‡∏≤‡∏î‡πÇ‡∏•‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÉ‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‚Üí is_relevant = false
3) ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏°‡∏î per_country:
   - ‡∏ñ‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà {feed_country} ‚Üí is_relevant = false
   - ‡∏ñ‡πâ‡∏≤ is_relevant = true ‚Üí country ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö "{feed_country}" ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
4) ‡∏ñ‡πâ‡∏≤‡πÇ‡∏´‡∏°‡∏î global:
   - ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å country = ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏´‡∏•‡∏±‡∏Å‡πÄ‡∏û‡∏µ‡∏¢‡∏á 1 ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÉ‡∏ô‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï
   - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏´‡∏•‡∏±‡∏Å ‚Üí is_relevant = false

‡∏ñ‡πâ‡∏≤ is_relevant = true ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏°:
- country: ‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ï‡∏≤‡∏°‡∏•‡∏¥‡∏™‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï
- projects: ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ô‡∏±‡πâ‡∏ô‡∏à‡∏≤‡∏Å context (‡∏ñ‡πâ‡∏≤‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà ["ALL"])
- impact_reason: bullet ‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î "‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£" ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡∏ï‡πâ‡∏ô‡∏ó‡∏∏‡∏ô/‡∏Å‡∏é‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö/‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏á‡∏≤‡∏ô/‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á)
- summary: ‡πÑ‡∏ó‡∏¢ 2‚Äì4 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ

‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏Ç‡πà‡∏≤‡∏ß:
‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {news['title']}
‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å RSS: {news['summary']}
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: {news.get('detail','')}

‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏ï‡∏≤‡∏° schema ‡∏ô‡∏µ‡πâ:
{json.dumps(schema, ensure_ascii=False)}
"""

    try:
        r = call_gemini(prompt, want_json=True)
        raw = (getattr(r, "text", "") or "").strip()
        data = _extract_json_object(raw)
        if not isinstance(data, dict):
            return rule_fallback(news)

        if "projects" in data and not isinstance(data.get("projects"), list):
            data["projects"] = [str(data["projects"])]

        return data
    except Exception:
        return rule_fallback(news)

# ============================================================================================================
# FETCH NEWS WINDOW (21:00 yesterday -> 06:00 today, Bangkok time)
# ============================================================================================================
def fetch_news_window():
    now_local = datetime.now(bangkok_tz)
    start = (now_local - timedelta(days=1)).replace(hour=21, minute=0, second=0, microsecond=0)
    end = now_local.replace(hour=6, minute=0, second=0, microsecond=0)

    out = []
    for site, feed_country, url in NEWS_FEEDS:
        try:
            feed = feedparser.parse(url)
            for e in feed.entries:
                pub = getattr(e, "published", None) or getattr(e, "updated", None)
                if not pub:
                    continue

                dt = dateutil_parser.parse(pub)
                if dt.tzinfo is None:
                    dt = pytz.UTC.localize(dt)
                dt = dt.astimezone(bangkok_tz)

                if start <= dt <= end:
                    title = getattr(e, "title", "") or ""
                    summary = getattr(e, "summary", "") or ""
                    text = f"{title} {summary}"
                    out.append({
                        "site": site,
                        "feed_country": feed_country,  # ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏Ç‡∏≠‡∏á feed ‡∏´‡∏£‡∏∑‡∏≠ "GLOBAL"
                        "title": title,
                        "summary": summary,
                        "link": getattr(e, "link", "") or "",
                        "published": dt,
                        "date": dt.strftime("%d/%m/%Y %H:%M"),
                        "countries_hint": detect_project_countries(text),
                    })
        except Exception:
            pass

    # dedupe ‡∏ï‡∏≤‡∏° link
    uniq = []
    seen = set()
    for n in out:
        k = _normalize_link(n["link"])
        if k and k not in seen:
            seen.add(k)
            uniq.append(n)

    uniq.sort(key=lambda x: x["published"], reverse=True)
    return uniq

# ============================================================================================================
# FLEX MESSAGE
# ============================================================================================================
def create_flex(news_items):
    now_txt = datetime.now(bangkok_tz).strftime("%d/%m/%Y")
    bubbles = []

    for n in news_items:
        bullets = _impact_to_bullets(n.get("impact_reason", ""))

        link = n.get("link") or ""
        if not (isinstance(link, str) and link.startswith(("http://", "https://"))):
            link = "https://news.google.com/"

        img = n.get("image") or DEFAULT_ICON_URL
        if not (isinstance(img, str) and img.startswith(("http://", "https://"))):
            img = DEFAULT_ICON_URL

        country_txt = (n.get("country") or "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏").strip()
        projects = n.get("projects") or []
        proj_txt = ", ".join(projects[:3]) if isinstance(projects, list) and projects else "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"

        body_contents = [
            {"type": "text", "text": n["title"], "weight": "bold", "size": "lg", "wrap": True},
            {"type": "text", "text": f"üóì {n['date']}", "size": "xs", "color": "#888888", "margin": "sm"},
            {"type": "text", "text": f"üåç {country_txt} | {n['site']}", "size": "xs", "color": "#448AFF", "margin": "xs"},
            {"type": "text", "text": f"‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£: {proj_txt} | ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®: {country_txt}", "size": "xs", "color": "#555555", "margin": "sm", "wrap": True},
        ]

        impact_box = {
            "type": "box",
            "layout": "vertical",
            "margin": "lg",
            "contents": [{"type": "text", "text": "‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£", "size": "lg", "weight": "bold", "color": "#000000"}]
            + [{"type": "text", "text": f"‚Ä¢ {b}", "wrap": True, "size": "md", "color": "#000000", "weight": "bold", "margin": "xs"} for b in bullets],
        }
        body_contents.append(impact_box)

        bubble = {
            "type": "bubble",
            "size": "mega",
            "hero": {"type": "image", "url": img, "size": "full", "aspectRatio": "16:9", "aspectMode": "cover"},
            "body": {"type": "box", "layout": "vertical", "contents": body_contents},
            "footer": {"type": "box", "layout": "vertical", "contents": [
                {"type": "button", "style": "primary", "color": "#1DB446",
                 "action": {"type": "uri", "label": "‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡πà‡∏≠", "uri": link}}
            ]},
        }
        bubbles.append(bubble)

    return [{
        "type": "flex",
        "altText": f"‡∏Ç‡πà‡∏≤‡∏ß PTTEP (Domestic) {now_txt}",
        "contents": {"type": "carousel", "contents": bubbles},
    }]

# ============================================================================================================
# BROADCAST LINE
# ============================================================================================================
def send_to_line(messages):
    url = "https://api.line.me/v2/bot/message/broadcast"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}",
    }

    for i, msg in enumerate(messages, 1):
        payload = {"messages": [msg]}
        print("=== LINE PAYLOAD ===")
        print(json.dumps(payload, ensure_ascii=False, indent=2))

        if DRY_RUN:
            print("[DRY_RUN] ‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ DRY_RUN = true")
            continue

        r = S.post(url, headers=headers, json=payload, timeout=15)
        print(f"Send {i}: {r.status_code}")
        print("Response body:", r.text)
        if r.status_code >= 300:
            break

# ============================================================================================================
# MAIN WORKFLOW
# ============================================================================================================
def main():
    print("‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß...")
    all_news = fetch_news_window()
    print("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:", len(all_news))
    if not all_news:
        print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤")
        return

    # ‡∏Å‡∏±‡∏ô‡∏™‡πà‡∏á‡∏ã‡πâ‡∏≥‡∏£‡∏≤‡∏¢‡∏ß‡∏±‡∏ô
    sent = load_sent_links()

    # 1) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å candidates ‡∏à‡∏≤‡∏Å GoogleNews per-country (‡∏Ñ‡∏∏‡∏°‡∏ï‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®)
    per_country_count = {c: 0 for c in PROJECT_COUNTRIES}
    candidates = []
    global_candidates = []

    for n in all_news:
        link_norm = _normalize_link(n.get("link", ""))
        if link_norm and link_norm in sent:
            continue

        feed_country = (n.get("feed_country") or "").strip()

        if feed_country in PROJECT_COUNTRIES:
            # per-country feeds
            if per_country_count.get(feed_country, 0) >= MAX_PER_COUNTRY:
                continue
            candidates.append(n)
            per_country_count[feed_country] = per_country_count.get(feed_country, 0) + 1
        else:
            # legacy/global feeds
            # ‡∏£‡∏±‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ñ‡πâ‡∏≤‡∏à‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ "‡∏ä‡∏±‡∏î" (‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1; ‡∏ñ‡πâ‡∏≤‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏à‡∏∞‡∏õ‡∏•‡πà‡∏≠‡∏¢‡πÉ‡∏´‡πâ LLM ‡∏ä‡∏µ‡πâ‡∏Ç‡∏≤‡∏î ‡πÅ‡∏ï‡πà‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏´‡∏•‡∏∏‡∏î‡∏™‡∏π‡∏á)
            global_candidates.append(n)

    # ‡∏Ñ‡∏∏‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô global feeds
    # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡∏ñ‡πâ‡∏≤ hint ‡∏°‡∏µ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1 ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏® ‡πÉ‡∏´‡πâ‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡πÄ‡∏≠‡∏≤‡∏ó‡πâ‡∏≤‡∏¢ ‡πÜ)
    global_candidates.sort(key=lambda x: (len(x.get("countries_hint") or []), x["published"]), reverse=False)
    global_candidates = global_candidates[:MAX_GLOBAL_ITEMS]

    # ‡∏£‡∏ß‡∏° candidates ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏∏‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏ß‡∏°‡∏ï‡πà‡∏≠‡∏£‡∏±‡∏ô
    combined = candidates + global_candidates
    combined = combined[:MAX_LLM_ITEMS]

    print("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ LLM:", len(combined),
          f"(per-country={len(candidates)}, global={len(global_candidates)})")

    tagged = []
    for idx, n in enumerate(combined, 1):
        print(f"[{idx}/{len(combined)}] LLM tag+filter: ({n.get('feed_country')}) {n['title'][:80]}...")
        n["detail"] = n["title"] if len(n.get("summary","")) < 50 else ""

        tag = gemini_tag_and_filter(n)
        if not tag.get("is_relevant"):
            time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))
            continue

        # ---- Final strict checks (‡∏´‡πâ‡∏≤‡∏°‡∏´‡∏•‡∏∏‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏≠‡∏∑‡πà‡∏ô) ----
        country_llm = (tag.get("country") or "").strip()
        if country_llm not in PROJECT_COUNTRIES:
            time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))
            continue

        feed_country = (n.get("feed_country") or "").strip()
        if feed_country in PROJECT_COUNTRIES:
            # per-country mode: ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö feed_country
            if country_llm != feed_country:
                time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))
                continue
        else:
            # global mode: ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 (‡∏Å‡∏±‡∏ô LLM ‡πÄ‡∏î‡∏≤)
            hints = n.get("countries_hint") or []
            if country_llm not in hints:
                time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))
                continue

        impact = tag.get("impact_reason", "") or ""
        if not has_meaningful_impact(impact):
            time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))
            continue

        n["topic_type"] = tag.get("topic_type", "other")
        n["region"] = tag.get("region", "other")
        n["impact_reason"] = impact
        n["summary_llm"] = tag.get("summary", "") or n.get("summary","") or n["title"]
        n["country"] = country_llm
        n["projects"] = tag.get("projects", []) or []

        tagged.append(n)
        time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))

    print("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô (domestic + strict country):", len(tagged))
    if not tagged:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô")
        return

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 10 ‡∏Ç‡πà‡∏≤‡∏ß
    selected = tagged[:10]

    # ‡∏´‡∏≤ hero image
    for n in selected:
        img = fetch_article_image(n.get("link", ""))
        if not (isinstance(img, str) and img.startswith(("http://", "https://"))):
            img = DEFAULT_ICON_URL
        n["image"] = img
        time.sleep(0.25)

    msgs = create_flex(selected)
    send_to_line(msgs)
    save_sent_links([n["link"] for n in selected])

    print("‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")

if __name__ == "__main__":
    main()
