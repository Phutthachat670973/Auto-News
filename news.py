# ============================================================================================================
# IMPORT & ENV
# ============================================================================================================
import os
import re
import json
import time
import random
from datetime import datetime, timedelta
from urllib.parse import urlparse, urlunparse, parse_qsl, urlencode

import feedparser
from dateutil import parser as dateutil_parser
import pytz
import requests
import google.generativeai as genai

try:
    from dotenv import load_dotenv
    load_dotenv()
except Exception:
    pass

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "").strip()

if not GEMINI_API_KEY:
    raise RuntimeError("‡πÑ‡∏°‡πà‡∏û‡∏ö GEMINI_API_KEY")

if not LINE_CHANNEL_ACCESS_TOKEN:
    raise RuntimeError("‡πÑ‡∏°‡πà‡∏û‡∏ö LINE_CHANNEL_ACCESS_TOKEN")

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel(os.getenv("GEMINI_MODEL_NAME", "gemini-2.5-flash"))

GEMINI_DAILY_BUDGET = int(os.getenv("GEMINI_DAILY_BUDGET", "250"))
MAX_RETRIES = 6

# ‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô‡∏´‡∏ô‡πà‡∏≠‡∏¢
SLEEP_BETWEEN_CALLS = (0.5, 1.0)

DRY_RUN = os.getenv("DRY_RUN", "false").lower() == "true"

# ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô "‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ LLM" ‡∏ï‡πà‡∏≠‡∏£‡∏±‡∏ô
MAX_LLM_ITEMS = int(os.getenv("MAX_LLM_ITEMS", "15"))

bangkok_tz = pytz.timezone("Asia/Bangkok")
now = datetime.now(bangkok_tz)

S = requests.Session()
S.headers.update({"User-Agent": "Mozilla/5.0"})
TIMEOUT = 15

SENT_LINKS_DIR = "sent_links"
os.makedirs(SENT_LINKS_DIR, exist_ok=True)

# ‡∏£‡∏π‡∏õ default ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö hero ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏π‡∏õ‡∏Ç‡πà‡∏≤‡∏ß‡∏à‡∏£‡∏¥‡∏á ‡πÜ
DEFAULT_ICON_URL = "https://scdn.line-apps.com/n/channel_devcenter/img/fx/01_1_cafe.png"


# ============================================================================================================
# PREFILTER KEYWORDS (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ LLM)
# ============================================================================================================
ENERGY_KEYWORDS = [
    "gas",
    "natural gas",
    "lng",
    "lpg",
    "pipeline",
    "gas field",
    "gasfield",
    "oil",
    "crude",
    "upstream",
    "offshore",
    "onshore",
    "drilling",
    "rig",
    "exploration",
    "production",
    "fsru",
    "regasification",
    "lnt terminal",
    "gas supply",
    "gas export",
    "gas import",
    "strike",
    "walkout",
    "sanction",
    "embargo",
    "energy policy",
    "energy minister",
    "electricity price",
]

COUNTRY_PARTNER_KEYWORDS = [
    # ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ PTTEP
    "thailand",
    "thai",
    "myanmar",
    "burma",
    "vietnam",
    "malaysia",
    "indonesia",
    "uae",
    "united arab emirates",
    "abu dhabi",
    "oman",
    "algeria",
    "mozambique",
    "australia",
    "brazil",
    "mexico",
    # ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á / ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
    "erawan",
    "bongkot",
    "arthit",
    "zawtika",
    "yadana",
    "yetagun",
    "rovuma",
    "ghasha",
    "montara",
    # ‡∏ú‡∏π‡πâ‡∏£‡πà‡∏ß‡∏°‡∏ó‡∏∏‡∏ô‡∏´‡∏•‡∏±‡∏Å
    "chevron",
    "exxon",
    "exxonmobil",
    "totalenergies",
    "shell",
    "bp",
    "eni",
    "sonatrach",
    "petrobras",
    "adnoc",
    "petronas",
]

def keyword_prefilter(news) -> bool:
    """
    ‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ LLM
    ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®/‡∏ú‡∏π‡πâ‡∏£‡πà‡∏ß‡∏°‡∏ó‡∏∏‡∏ô‡πÉ‡∏ô title+summary ‚Üí ‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô
    """
    text = (news.get("title", "") + " " + news.get("summary", "")).lower()

    if any(k in text for k in ENERGY_KEYWORDS):
        return True
    if any(k in text for k in COUNTRY_PARTNER_KEYWORDS):
        return True

    return False


# ============================================================================================================
# HELPERS
# ============================================================================================================
def _normalize_link(url: str) -> str:
    try:
        p = urlparse(url)
        netloc = p.netloc.lower()
        scheme = (p.scheme or "https").lower()

        drop = {"fbclid", "gclid", "ref", "mc_cid", "mc_eid"}
        new_q = [
            (k, v)
            for k, v in parse_qsl(p.query, keep_blank_values=True)
            if not (k.startswith("utm_") or k in drop)
        ]

        return urlunparse(
            p._replace(
                scheme=scheme,
                netloc=netloc,
                query=urlencode(new_q),
            )
        )
    except Exception:
        return (url or "").strip()


def get_sent_links_file(date=None):
    if date is None:
        date = datetime.now(bangkok_tz).strftime("%Y-%m-%d")
    return os.path.join(SENT_LINKS_DIR, f"{date}.txt")


def load_sent_links():
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏™‡πà‡∏á '‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏±‡∏ô‡∏™‡πà‡∏á‡∏ã‡πâ‡∏≥‡πÉ‡∏ô‡∏ß‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    """
    sent = set()
    today_str = datetime.now(bangkok_tz).strftime("%Y-%m-%d")
    p = get_sent_links_file(today_str)

    if os.path.exists(p):
        with open(p, "r", encoding="utf-8") as f:
            for line in f:
                u = _normalize_link(line.strip())
                if u:
                    sent.add(u)

    return sent


def save_sent_links(links):
    p = get_sent_links_file()
    with open(p, "a", encoding="utf-8") as f:
        for l in links:
            f.write(_normalize_link(l) + "\n")


def _impact_to_bullets(text: str):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° impact_reason ‡πÄ‡∏õ‡πá‡∏ô list bullet ‡∏™‡∏∞‡∏≠‡∏≤‡∏î ‡πÜ
    """
    if not text:
        return ["‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£"]

    lines = [l.strip() for l in text.splitlines() if l.strip()]
    if not lines:
        lines = [text.strip()]

    bullets = []
    for line in lines:
        s = line.strip()
        s = re.sub(r"^[\u2022\*\-\u00b7¬∑‚Ä¢\s]+", "", s)
        s = re.sub(r"^\d+[\.\)]\s*", "", s)
        if s.startswith(".*"):
            s = s[2:].lstrip()
        if s.startswith("*"):
            s = s[1:].lstrip()
        if s:
            bullets.append(s)

    return bullets or ["‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£"]


def has_meaningful_impact(impact_text: str) -> bool:
    """
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ False ‡∏ñ‡πâ‡∏≤ impact_text ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ô‡∏ß
    '‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á PTTEP'
    """
    if not impact_text:
        return False

    t = impact_text.lower().replace(" ", "")
    patterns = [
        "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏ápttep",
        "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏ápttep",
        "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏ápttep",
    ]
    for p in patterns:
        if p in t:
            return False

    return True


# ============================================================================================================
# ‡∏î‡∏∂‡∏á‡∏£‡∏π‡∏õ‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏Ç‡πà‡∏≤‡∏ß (og:image / twitter:image / <img> ‡πÅ‡∏£‡∏Å)
# ============================================================================================================
def fetch_article_image(url: str) -> str:
    if not url:
        return ""

    try:
        r = S.get(url, timeout=TIMEOUT)
        if r.status_code >= 400:
            return ""

        html = r.text

        m = re.search(
            r'<meta[^>]+property=[\'"]og:image[\'"][^>]+content=[\'"]([^\'"]+)[\'"]',
            html,
            re.I,
        )
        if m:
            return m.group(1)

        m = re.search(
            r'<meta[^>]+name=[\'"]twitter:image[\'"][^>]+content=[\'"]([^\'"]+)[\'"]',
            html,
            re.I,
        )
        if m:
            return m.group(1)

        m = re.search(r'<img[^>]+src=[\'"]([^\'"]+)[\'"]', html, re.I)
        if m:
            src = m.group(1)
            if src.startswith("//"):
                parsed = urlparse(url)
                return f"{parsed.scheme}:{src}"
            if src.startswith("/"):
                parsed = urlparse(url)
                return f"{parsed.scheme}://{parsed.netloc}{src}"
            return src

        return ""
    except Exception:
        return ""


# ============================================================================================================
# CONTEXT
# ============================================================================================================
PTT_CONTEXT = r"""
[‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á ‡∏õ‡∏ï‡∏ó.]

‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à
- ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ô‡∏µ‡πâ‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏≤‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®
- ‡∏î‡∏π‡πÅ‡∏•‡∏´‡πà‡∏ß‡∏á‡πÇ‡∏ã‡πà‡∏≠‡∏∏‡∏õ‡∏ó‡∏≤‡∏ô‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à ‡∏ú‡∏•‡∏¥‡∏ï ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ ‡πÅ‡∏õ‡∏£‡∏£‡∏π‡∏õ ‡∏Ç‡∏ô‡∏™‡πà‡∏á ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏´‡∏ô‡πà‡∏≤‡∏¢
- ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏´‡∏•‡∏±‡∏Å: ‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥ (NG), ‡∏Å‡πä‡∏≤‡∏ã‡∏õ‡∏¥‡πÇ‡∏ï‡∏£‡πÄ‡∏•‡∏µ‡∏¢‡∏°‡πÄ‡∏´‡∏•‡∏ß (LPG), ‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡∏≤‡∏ô‡∏¢‡∏ô‡∏ï‡πå (NGV)
- ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡πä‡∏≤‡∏ã‡∏ò‡∏£‡∏£‡∏°‡∏ä‡∏≤‡∏ï‡∏¥‡πÄ‡∏´‡∏•‡∏ß (LNG) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏£‡∏¥‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®
"""

PTTEP_PROJECTS_CONTEXT = r"""
[PTTEP_PROJECTS_CONTEXT]

‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢ (Thailand)
- G1/61 (Erawan, Platong, Satun, Funan)
- G2/61 (Bongkot ‡πÅ‡∏•‡∏∞‡πÅ‡∏´‡∏•‡πà‡∏á‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á)
- Arthit, S1, Contract 4, B8/32, 9A, Sinphuhorm, MTJDA Block A-18

‡πÄ‡∏°‡∏µ‡∏¢‡∏ô‡∏°‡∏≤ (Myanmar) ‚Äì Zawtika, Yadana, Yetagun
‡πÄ‡∏ß‡∏µ‡∏¢‡∏î‡∏ô‡∏≤‡∏° (Vietnam) ‚Äì Block B & 48/95, Block 52/97, 16-1 (Te Giac Trang)
‡∏°‡∏≤‡πÄ‡∏•‡πÄ‡∏ã‡∏µ‡∏¢ (Malaysia) ‚Äì MTJDA Block A-18, SK309, SK311, SK410B ‡∏Ø‡∏•‡∏Ø
‡∏≠‡∏¥‡∏ô‡πÇ‡∏î‡∏ô‡∏µ‡πÄ‡∏ã‡∏µ‡∏¢ (Indonesia) ‚Äì South Sageri, South Mandar, Malunda ‡∏Ø‡∏•‡∏Ø
UAE ‚Äì Ghasha Concession, Abu Dhabi Offshore
Oman ‚Äì Oman Block 12
Algeria ‚Äì Bir Seba, Hirad, Touat ‡∏Ø‡∏•‡∏Ø
Mozambique ‚Äì Mozambique Area 1 (Rovuma LNG)
Australia ‚Äì Montara ‡πÅ‡∏•‡∏∞‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏∑‡πà‡∏ô ‡πÜ ‡πÉ‡∏ô Timor Sea / Browse Basin
Brazil ‚Äì BM-ES-23, BM-ES-24 ‡∏Ø‡∏•‡∏Ø
Mexico ‚Äì Mexico Block 12 (2.4) ‡πÅ‡∏•‡∏∞‡∏ö‡∏•‡πá‡∏≠‡∏Å‡∏≠‡∏∑‡πà‡∏ô ‡πÜ
"""


# ============================================================================================================
# GEMINI CALL WRAPPER
# ============================================================================================================
GEMINI_CALLS = 0


def call_gemini(prompt):
    global GEMINI_CALLS

    if GEMINI_CALLS >= GEMINI_DAILY_BUDGET:
        raise RuntimeError("‡πÄ‡∏Å‡∏¥‡∏ô‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤ Gemini ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô")

    last_error = None
    for i in range(1, MAX_RETRIES + 1):
        try:
            r = model.generate_content(prompt)
            GEMINI_CALLS += 1
            return r
        except Exception as e:
            last_error = e
            if (
                any(x in str(e) for x in ["429", "unavailable", "deadline", "503", "500"])
                and i < MAX_RETRIES
            ):
                time.sleep(5 * i)
                continue
            raise e

    raise last_error


# ============================================================================================================
# GEMINI TAG + FILTER (‡∏£‡∏ß‡∏°‡∏™‡∏≠‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
# ============================================================================================================
def gemini_tag_and_filter(news):
    schema = {
        "type": "object",
        "properties": {
            "is_relevant": {"type": "boolean"},
            "summary": {"type": "string"},
            "topic_type": {
                "type": "string",
                "enum": [
                    "supply_disruption",
                    "price_move",
                    "policy",
                    "investment",
                    "geopolitics",
                    "other",
                ],
            },
            "region": {
                "type": "string",
                "enum": ["global", "asia", "europe", "middle_east", "us", "other"],
            },
            "impact_reason": {"type": "string"},
            "country": {"type": "string"},
            "projects": {
                "type": "array",
                "items": {"type": "string"},
            },
        },
        "required": ["is_relevant"],
    }

    prompt = f"""
{PTT_CONTEXT}
{PTTEP_PROJECTS_CONTEXT}

[‡∏û‡∏±‡∏ô‡∏ò‡∏°‡∏¥‡∏ï‡∏£ / ‡∏ú‡∏π‡πâ‡∏£‡πà‡∏ß‡∏°‡∏ó‡∏∏‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢]
- Chevron, ExxonMobil, TotalEnergies, Shell, BP, ENI, Sonatrach, Petrobras,
  ADNOC, Petronas ‡πÅ‡∏•‡∏∞‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡πÅ‡∏´‡πà‡∏á‡∏ä‡∏≤‡∏ï‡∏¥‡∏≠‡∏∑‡πà‡∏ô ‡πÜ

‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì: Analyst + News Screener ‡∏Ç‡∏≠‡∏á PTTEP

‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô is_relevant
‡πÉ‡∏´‡πâ is_relevant = true ‡∏ñ‡πâ‡∏≤‡∏Ç‡πà‡∏≤‡∏ß‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Å‡∏£‡∏∞‡∏ó‡∏ö "‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏¥‡∏ï/‡∏Å‡πä‡∏≤‡∏ã" ‡∏Ç‡∏≠‡∏á PTTEP ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏£‡πà‡∏ß‡∏°‡∏ó‡∏∏‡∏ô
‡∏ú‡πà‡∏≤‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÄ‡∏ä‡πà‡∏ô:
- ‡∏Ç‡πà‡∏≤‡∏ß‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô (oil/gas/LNG/pipeline/upstream) ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á PTTEP
- ‡∏Ç‡πà‡∏≤‡∏ß‡∏Å‡∏≤‡∏£‡πÄ‡∏°‡∏∑‡∏≠‡∏á ‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢ ‡∏†‡∏≤‡∏©‡∏µ ‡∏™‡∏±‡∏°‡∏õ‡∏ó‡∏≤‡∏ô ‡∏°‡∏≤‡∏ï‡∏£‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡πà‡∏≥‡∏ö‡∏≤‡∏ï‡∏£ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡∏Ñ‡∏á ‡∏™‡∏á‡∏Ñ‡∏£‡∏≤‡∏° ‡∏õ‡∏£‡∏∞‡∏ó‡πâ‡∏ß‡∏á‡πÅ‡∏£‡∏á‡∏á‡∏≤‡∏ô
  ‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á PTTEP ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏£‡πà‡∏ß‡∏°‡∏ó‡∏∏‡∏ô‡∏´‡∏•‡∏±‡∏Å
- ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏∞‡∏ó‡∏ö supply / cost / schedule ‡∏Ç‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ

‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô downstream, EV, lifestyle, PR ‡∏Ø‡∏•‡∏Ø ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÇ‡∏¢‡∏á‡∏Å‡∏±‡∏ö upstream/‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢‡∏û‡∏•‡∏±‡∏á‡∏á‡∏≤‡∏ô‡πÄ‡∏•‡∏¢ ‚Üí is_relevant = false

‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏ô‡πÄ‡∏≠‡∏µ‡∏¢‡∏á‡πÑ‡∏õ‡∏ó‡∏≤‡∏á is_relevant = true
(‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏±‡∏î‡∏ó‡∏¥‡πâ‡∏á‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)

‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ó‡∏µ‡πà 2: ‡∏ñ‡πâ‡∏≤ is_relevant = true ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ
- summary: ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πà‡∏≤‡∏ß‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ 2‚Äì4 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ
- topic_type, region: ‡πÅ‡∏ó‡πá‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πà‡∏≤‡∏ß/‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ
- impact_reason:
  * ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ "‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á PTTEP" ‡πÄ‡∏õ‡πá‡∏ô bullet ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏•‡∏≤‡∏¢‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
  * ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ä‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®/‡∏ö‡∏•‡πá‡∏≠‡∏Å/‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô context
  * ‡∏ñ‡πâ‡∏≤ "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á" ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÅ‡∏ö‡∏ö‡∏ô‡∏±‡πâ‡∏ô‡πÑ‡∏î‡πâ
- country: ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (‡πÄ‡∏ä‡πà‡∏ô Thailand, Myanmar, US, Mozambique, UAE ‡∏Ø‡∏•‡∏Ø)
- projects: ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á PTTEP ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (‡πÄ‡∏ä‡πà‡∏ô ["G1/61", "Mozambique Area 1"])

‡∏≠‡∏¥‡∏ô‡∏û‡∏∏‡∏ï‡∏Ç‡πà‡∏≤‡∏ß:
‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠: {news['title']}
‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å RSS: {news['summary']}
‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: {news.get('detail','')}

‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô JSON ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏ï‡∏≤‡∏° schema ‡∏ô‡∏µ‡πâ:
{json.dumps(schema, ensure_ascii=False)}
"""

    try:
        r = call_gemini(prompt)
        raw = (r.text or "").strip()

        if raw.startswith("```"):
            raw = re.sub(r"^```(json)?", "", raw).strip()
            raw = re.sub(r"```$", "", raw).strip()

        return json.loads(raw)
    except Exception:
        return {"is_relevant": False}


# ============================================================================================================
# FETCH NEWS
# ============================================================================================================
NEWS_FEEDS = [
    ("Oilprice", "Energy", "https://oilprice.com/rss/main"),
    ("CleanTechnica", "Energy", "https://cleantechnica.com/feed/"),
    ("HydrogenFuelNews", "Energy", "https://www.hydrogenfuelnews.com/feed/"),
    ("Economist", "Economy", "https://www.economist.com/latest/rss.xml"),
    ("YahooFinance", "Economy", "https://finance.yahoo.com/news/rssindex"),
]


def fetch_news_window():
    now_local = datetime.now(bangkok_tz)

    # ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 21:00 ‡∏Ç‡∏≠‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏≤‡∏ô ‡∏ñ‡∏∂‡∏á 06:00 ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ
    start = (now_local - timedelta(days=1)).replace(
        hour=21, minute=0, second=0, microsecond=0
    )
    end = now_local.replace(hour=6, minute=0, second=0, microsecond=0)

    out = []

    for site, cat, url in NEWS_FEEDS:
        try:
            feed = feedparser.parse(url)
            for e in feed.entries:
                pub = getattr(e, "published", None) or getattr(e, "updated", None)
                if not pub:
                    continue

                dt = dateutil_parser.parse(pub)
                if dt.tzinfo is None:
                    dt = pytz.UTC.localize(dt)
                dt = dt.astimezone(bangkok_tz)

                if start <= dt <= end:
                    out.append(
                        {
                            "site": site,
                            "category": cat,
                            "title": e.title,
                            "summary": getattr(e, "summary", ""),
                            "link": e.link,
                            "published": dt,
                            "date": dt.strftime("%d/%m/%Y %H:%M"),
                        }
                    )
        except Exception:
            pass

    # dedupe ‡∏ï‡∏≤‡∏° link
    uniq = []
    seen = set()
    for n in out:
        k = _normalize_link(n["link"])
        if k not in seen:
            seen.add(k)
            uniq.append(n)

    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏õ‡πÄ‡∏Å‡πà‡∏≤
    uniq.sort(key=lambda x: x["published"], reverse=True)
    return uniq


# ============================================================================================================
# FLEX MESSAGE
# ============================================================================================================
def create_flex(news_items):
    now_txt = datetime.now(bangkok_tz).strftime("%d/%m/%Y")
    bubbles = []

    for n in news_items:
        bullets = _impact_to_bullets(n.get("impact_reason", "-"))

        link = n.get("link") or ""
        if not (isinstance(link, str) and link.startswith(("http://", "https://"))):
            link = "https://www.google.com/search?q=energy+gas+news"

        img = n.get("image") or DEFAULT_ICON_URL
        if not (isinstance(img, str) and img.startswith(("http://", "https://"))):
            img = DEFAULT_ICON_URL

        country_txt = (n.get("country") or "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏").strip()
        projects = n.get("projects") or []
        if isinstance(projects, list):
            proj_txt = ", ".join(projects[:3]) if projects else "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
        else:
            proj_txt = str(projects)

        body_contents = [
            {
                "type": "text",
                "text": n["title"],
                "weight": "bold",
                "size": "lg",
                "wrap": True,
            },
            {
                "type": "text",
                "text": f"üóì {n['date']}",
                "size": "xs",
                "color": "#888888",
                "margin": "sm",
            },
            {
                "type": "text",
                "text": f"üåç {n['site']}",
                "size": "xs",
                "color": "#448AFF",
                "margin": "xs",
            },
            {
                "type": "text",
                "text": f"‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£: {proj_txt} | ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®: {country_txt}",
                "size": "xs",
                "color": "#555555",
                "margin": "sm",
                "wrap": True,
            },
        ]

        impact_box = {
            "type": "box",
            "layout": "vertical",
            "margin": "lg",
            "contents": [
                {
                    "type": "text",
                    "text": "‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£",
                    "size": "lg",
                    "weight": "bold",
                    "color": "#000000",
                }
            ]
            + [
                {
                    "type": "text",
                    "text": f"‚Ä¢ {b}",
                    "wrap": True,
                    "size": "md",
                    "color": "#000000",
                    "weight": "bold",
                    "margin": "xs",
                }
                for b in bullets
            ],
        }

        body_contents.append(impact_box)

        bubble = {
            "type": "bubble",
            "size": "mega",
            "hero": {
                "type": "image",
                "url": img,
                "size": "full",
                "aspectRatio": "16:9",
                "aspectMode": "cover",
            },
            "body": {
                "type": "box",
                "layout": "vertical",
                "contents": body_contents,
            },
            "footer": {
                "type": "box",
                "layout": "vertical",
                "contents": [
                    {
                        "type": "button",
                        "style": "primary",
                        "color": "#1DB446",
                        "action": {
                            "type": "uri",
                            "label": "‡∏≠‡πà‡∏≤‡∏ô‡∏ï‡πà‡∏≠",
                            "uri": link,
                        },
                    }
                ],
            },
        }

        bubbles.append(bubble)

    return [
        {
            "type": "flex",
            "altText": f"‡∏Ç‡πà‡∏≤‡∏ß PTTEP {now_txt}",
            "contents": {"type": "carousel", "contents": bubbles},
        }
    ]


# ============================================================================================================
# BROADCAST LINE
# ============================================================================================================
def send_to_line(messages):
    url = "https://api.line.me/v2/bot/message/broadcast"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}",
    }

    for i, msg in enumerate(messages, 1):
        payload = {"messages": [msg]}

        print("=== LINE PAYLOAD ===")
        print(json.dumps(payload, ensure_ascii=False, indent=2))

        if DRY_RUN:
            print("[DRY_RUN] ‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏à‡∏£‡∏¥‡∏á ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ DRY_RUN = true")
            continue

        r = S.post(url, headers=headers, json=payload, timeout=15)
        print(f"Send {i}: {r.status_code}")
        print("Response body:", r.text)

        if r.status_code >= 300:
            break


# ============================================================================================================
# MAIN WORKFLOW
# ============================================================================================================
def main():
    print("‡∏î‡∏∂‡∏á‡∏Ç‡πà‡∏≤‡∏ß...")
    all_news = fetch_news_window()
    print("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏î‡∏¥‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î:", len(all_news))

    # pre-filter ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ LLM
    candidates = [n for n in all_news if keyword_prefilter(n)]
    print("‡∏´‡∏•‡∏±‡∏á keyword pre-filter:", len(candidates))

    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ LLM
    if len(candidates) > MAX_LLM_ITEMS:
        candidates = candidates[:MAX_LLM_ITEMS]
        print(f"‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ LLM ‡πÄ‡∏´‡∏•‡∏∑‡∏≠: {len(candidates)} (MAX_LLM_ITEMS)")

    tagged = []
    for idx, n in enumerate(candidates, 1):
        print(f"[{idx}/{len(candidates)}] LLM tag+filter: {n['title'][:80]}...")
        n["detail"] = n["title"] if len(n["summary"]) < 50 else ""

        tag = gemini_tag_and_filter(n)

        if not tag.get("is_relevant"):
            time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))
            continue

        n["topic_type"] = tag.get("topic_type", "other")
        n["region"] = tag.get("region", "other")
        n["impact_reason"] = tag.get(
            "impact_reason", "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏á PTTEP"
        )
        n["summary_llm"] = (
            tag.get("summary")
            or n.get("summary")
            or n["title"]
        )
        n["country"] = tag.get("country", "")
        n["projects"] = tag.get("projects", [])

        if not has_meaningful_impact(n["impact_reason"]):
            time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))
            continue

        tagged.append(n)
        time.sleep(random.uniform(*SLEEP_BETWEEN_CALLS))

    print("‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏£‡∏¥‡∏á ‡πÜ:", len(tagged))
    if not tagged:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö‡∏ï‡πà‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô")
        return

    selected = tagged[:10]

    sent = load_sent_links()
    final = [n for n in selected if _normalize_link(n["link"]) not in sent]
    print("‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏±‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤:", len(final))

    if not final:
        print("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πà‡∏≤‡∏ß‡πÉ‡∏´‡∏°‡πà")
        return

    for n in final:
        img = fetch_article_image(n.get("link", ""))
        if not (isinstance(img, str) and img.startswith(("http://", "https://"))):
            img = DEFAULT_ICON_URL
        n["image"] = img
        time.sleep(0.3)

    msgs = create_flex(final)
    send_to_line(msgs)
    save_sent_links([n["link"] for n in final])

    print("‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô")


# ============================================================================================================
if __name__ == "__main__":
    main()
